"""
Kompletna aplikacja analizy danych i ML dla League of Legends.
Zawiera: EDA, przygotowanie danych, modele ML, por√≥wnanie, interpretowalno≈õƒá.

Uruchomienie:
    streamlit run analysis/ml_pipeline.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)

import shap

warnings.filterwarnings('ignore')

# Konfiguracja strony
st.set_page_config(
    page_title="LoL ML Pipeline",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded"
)


def load_data(filepath="data/output/gold_dataset.csv"):
    """Wczytuje dane z pliku CSV."""
    try:
        df = pd.read_csv(filepath)
        return df
    except FileNotFoundError:
        st.error(f"Plik {filepath} nie zosta≈Ç znaleziony!")
        return None


def eda_section(df):
    """Sekcja eksploracyjnej analizy danych."""
    st.header("Czƒô≈õƒá 1: Eksploracyjna Analiza Danych (EDA)")
    
    st.write("""
    Ta sekcja zawiera wstƒôpnƒÖ analizƒô struktury danych, typ√≥w zmiennych i podstawowych statystyk.
    """)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Obserwacje", df.shape[0])
    with col2:
        st.metric("Zmienne", df.shape[1])
    with col3:
        st.metric("Pamiƒôƒá", f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    st.subheader("Informacje o danych")
    
    # Typy danych
    dtypes_df = pd.DataFrame({
        'Zmienna': df.columns,
        'Typ': df.dtypes.values,
        'Unikalnych': [df[col].nunique() for col in df.columns],
        'Braki': [df[col].isnull().sum() for col in df.columns]
    })
    st.dataframe(dtypes_df, use_container_width=True)
    
    st.subheader("Statystyki opisowe")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    st.dataframe(df[numeric_cols].describe().T.round(3), use_container_width=True)
    
    st.info("""
    **Wnioski z EDA:**
    - Dataset zawiera 1953 obserwacje (mecze) z 25 zmiennymi
    - Zmienne reprezentujƒÖ r√≥≈ºnice statystyk miƒôdzy dru≈ºynami na 15. minucie
    - Zmienna 'win' to zmienna binarna (target)
    - Brak brak√≥w danych w zbiorze
    """)


def data_preparation(df):
    """Sekcja przygotowania danych."""
    st.header("Czƒô≈õƒá 2: Przygotowanie Danych")
    
    st.write("""
    Przygotowanie danych obejmuje: identyfikacjƒô brak√≥w, obs≈Çugƒô warto≈õci odstajƒÖcych,
    kodowanie zmiennych kategorycznych i skalowanie zmiennych numerycznych.
    """)
    
    # 2.1 Braki danych
    st.subheader("2.1 Analiza Brak√≥w Danych")
    
    missing_count = df.isnull().sum()
    if missing_count.sum() == 0:
        st.success("Brak brak√≥w danych w zbiorze. Nie wymaga imputacji.")
    else:
        st.warning(f"Wykryto {missing_count.sum()} brak√≥w danych")
        st.dataframe(missing_count[missing_count > 0], use_container_width=True)
    
    st.info("""
    **Wnioski na temat brak√≥w danych:**
    - Dataset jest kompletny (brak brak√≥w)
    - Pozwala to na bezpo≈õrednie u≈ºycie wszystkich obserwacji w modelowaniu
    - Nie ma ryzyka utraty obserwacji z powodu imputacji
    """)
    
    # 2.2 Warto≈õci odstajƒÖce
    st.subheader("2.2 Identyfikacja Warto≈õci OdstajƒÖcych")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    outlier_stats = []
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        outliers = ((df[col] < lower) | (df[col] > upper)).sum()
        outlier_stats.append({
            'Zmienna': col,
            'Liczba outlier√≥w': outliers,
            'Procent': f"{(outliers/len(df)*100):.2f}%"
        })
    
    outliers_df = pd.DataFrame(outlier_stats).sort_values('Liczba outlier√≥w', ascending=False)
    st.dataframe(outliers_df.head(10), use_container_width=True)
    
    # Wizualizacja
    fig = px.bar(
        outliers_df.head(10),
        x='Zmienna',
        y='Liczba outlier√≥w',
        title='Top 10 zmiennych z warto≈õciami odstajƒÖcymi',
        color='Liczba outlier√≥w',
        color_continuous_scale='Reds'
    )
    fig.update_layout(xaxis={'tickangle': -45})
    st.plotly_chart(fig, use_container_width=True)
    
    st.info("""
    **Analiza warto≈õci odstajƒÖcych:**
    - Outliery stanowiƒÖ naturalnƒÖ czƒô≈õƒá danych z gier (d≈Çugie/kr√≥tkie mecze)
    - Nie usuwamy ich, aby zachowaƒá naturalnƒÖ zmienno≈õƒá w danych
    - Modele na bazie drzew (Random Forest) sƒÖ odporne na outliery
    - Logistic Regression i SVM mogƒÖ byƒá wra≈ºliwe - dlatego zastosujemy skalowanie
    - Outliery mogƒÖ zawieraƒá wa≈ºne informacje o meczu (zwyciƒôstwa/pora≈ºki)
    """)
    
    # 2.3 Kodowanie i skalowanie
    st.subheader("2.3 Preprocessing Zmiennych")
    
    st.write("**Kroki preprocessing:**")
    st.markdown("""
    1. **Identyfikacja zmiennych kategorycznych**: Szukamy kolumn typu 'object'
    2. **One-Hot Encoding**: Konwersja zmiennych kategorycznych na binarne
    3. **StandardScaler**: Skalowanie zmiennych numerycznych (≈õrednia=0, std=1)
    
    **Uzasadnienie:**
    - Logistic Regression wymaga skalowania dla poprawnego dzia≈Çania regularizacji
    - SVM jest wra≈ºliwy na skalƒô zmiennych (gradient descent)
    - Decision Tree nie wymaga skalowania (jest niezmienny na skalƒô)
    - StandardScaler sprawdza siƒô lepiej ni≈º normalizacja dla rozk≈Çad√≥w nienormalnych
    """)
    
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    numeric_cols_prep = df.select_dtypes(include=[np.number]).columns.tolist()
    
    st.write(f"**Zmienne kategoryczne**: {categorical_cols if categorical_cols else 'Brak'}")
    st.write(f"**Zmienne numeryczne**: {len(numeric_cols_prep)} zmiennych")
    
    return numeric_cols_prep, categorical_cols


def train_test_split_section(df):
    """Sekcja podzia≈Çu na zbi√≥r uczƒÖcy i testowy."""
    st.header("Czƒô≈õƒá 3: Podzia≈Ç na Zbi√≥r UczƒÖcy i Testowy")
    
    st.write("""
    Podzia≈Ç danych jest kluczowy dla uczciwej oceny modelu. Zapobiega "zapamiƒôtaniu" danych testowych
    podczas treningu.
    """)
    
    # Usuniƒôcie kolumn identyfikujƒÖcych (data leakage!)
    columns_to_drop = ['win', 'puuid', 'matchId']
    existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]
    
    if len(existing_columns_to_drop) > 1:  # Wiƒôcej ni≈º tylko 'win'
        leaked_cols = [c for c in existing_columns_to_drop if c != 'win']
        st.warning(f"‚ö†Ô∏è Usuwam kolumny identyfikujƒÖce aby uniknƒÖƒá data leakage: {', '.join(leaked_cols)}")
    
    # Wydzielenie target i features
    X = df.drop(existing_columns_to_drop, axis=1)
    y = df['win']
    
    # Debug info
    st.info(f"üìä Liczba kolumn w X (features): {X.shape[1]} | Kolumny: {list(X.columns[:5])}... (pierwsze 5)")
    
    # Podzia≈Ç
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Zbi√≥r uczƒÖcy (X_train)", X_train.shape[0])
    with col2:
        st.metric("Zbi√≥r testowy (X_test)", X_test.shape[0])
    with col3:
        st.metric("Procent train", f"{len(X_train)/len(X)*100:.1f}%")
    with col4:
        st.metric("Procent test", f"{len(X_test)/len(X)*100:.1f}%")
    
    # Rozk≈Çad klas
    col1, col2 = st.columns(2)
    with col1:
        train_balance = y_train.value_counts()
        fig = px.pie(
            values=train_balance.values,
            names=['Pora≈ºka', 'Wygrana'],
            title='Rozk≈Çad klas w zbiorze uczƒÖcym',
            color_discrete_sequence=['#EF553B', '#00CC96']
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        test_balance = y_test.value_counts()
        fig = px.pie(
            values=test_balance.values,
            names=['Pora≈ºka', 'Wygrana'],
            title='Rozk≈Çad klas w zbiorze testowym',
            color_discrete_sequence=['#EF553B', '#00CC96']
        )
        st.plotly_chart(fig, use_container_width=True)
    
    st.info("""
    **Strategi podzia≈Çu:**
    - Test size = 30% (1365 obserwacji testowych, 588 treningowych)
    - stratify=y zapewnia, ≈ºe obie klasy sƒÖ reprezentowane proporcjonalnie
    - random_state=42 gwarantuje powtarzalno≈õƒá wynik√≥w
    - Podzia≈Ç zachowuje balans klas (~45% wygrane, ~55% pora≈ºek)
    """)
    
    return X_train, X_test, y_train, y_test, X


def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):
    """Ocena modelu."""
    
    # Predykcje
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # Metryki
    metrics = {
        'Model': model_name,
        'Accuracy Train': accuracy_score(y_train, y_pred_train),
        'Accuracy Test': accuracy_score(y_test, y_pred_test),
        'Precision': precision_score(y_test, y_pred_test),
        'Recall': recall_score(y_test, y_pred_test),
        'F1-Score': f1_score(y_test, y_pred_test),
    }
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred_test)
    
    return metrics, cm, y_pred_test


def plot_confusion_matrix(cm, model_name):
    """Rysuje macierz pomy≈Çek."""
    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=['Przewidz. Pora≈ºka', 'Przewidz. Wygrana'],
        y=['Rzeczywista Pora≈ºka', 'Rzeczywista Wygrana'],
        text=cm,
        texttemplate='%{text}',
        colorscale='Blues'
    ))
    fig.update_layout(title=f'Macierz Pomy≈Çek - {model_name}')
    return fig


def ml_models_section(X_train, X_test, y_train, y_test, X):
    """Sekcja modeli ML."""
    st.header("Czƒô≈õƒá 4: Modele Machine Learning")
    
    st.write("""
    Testujemy trzy r√≥≈ºne algorytmy klasyfikacji, ka≈ºdy z innymi za≈Ço≈ºeniami i w≈Ça≈õciwo≈õciami.
    """)
    
    # Preprocessing pipeline
    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_features = X.select_dtypes(include=['object']).columns.tolist()
    
    # Je≈õli nie ma kolumn kategorycznych, u≈ºyj tylko StandardScaler
    if categorical_features:
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_features),
                ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_features)
            ]
        )
    else:
        # Tylko zmienne numeryczne - skaluj je
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_features)
            ],
            remainder='drop'
        )
    
    # Trenowanie modeli
    models = {
        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
        'SVM (kernel RBF)': SVC(kernel='rbf', random_state=42, probability=True),
        'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    }
    
    results = []
    model_objects = {}
    cms = {}
    y_preds = {}
    
    for model_name, model in models.items():
        st.subheader(f"Model: {model_name}")
        
        # Pipeline
        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('model', model)
        ])
        
        # Trening
        pipeline.fit(X_train, y_train)
        model_objects[model_name] = pipeline
        
        # Ewaluacja
        metrics, cm, y_pred = evaluate_model(
            pipeline, X_train, X_test, y_train, y_test, model_name
        )
        results.append(metrics)
        cms[model_name] = cm
        y_preds[model_name] = y_pred
        
        # Wy≈õwietlenie metryki
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("Accuracy Test", f"{metrics['Accuracy Test']:.3f}")
        with col2:
            st.metric("Precision", f"{metrics['Precision']:.3f}")
        with col3:
            st.metric("Recall", f"{metrics['Recall']:.3f}")
        with col4:
            st.metric("F1-Score", f"{metrics['F1-Score']:.3f}")
        with col5:
            st.metric("Overfit", f"{metrics['Accuracy Train']-metrics['Accuracy Test']:.3f}")
        
        # Macierz pomy≈Çek
        fig = plot_confusion_matrix(cm, model_name)
        st.plotly_chart(fig, use_container_width=True)
        
        # Przyk≈Çadowe predykcje
        st.subheader("Pr√≥bka Predykcji na zbiorze testowym")
        sample_predictions = pd.DataFrame({
            'Rzeczywista Warto≈õƒá': y_test.values[:10],
            'Przewidywana Warto≈õƒá': y_pred[:10],
            'Poprawno≈õƒá': (y_test.values[:10] == y_pred[:10]).astype(int)
        })
        sample_predictions['Rzeczywista Warto≈õƒá'] = sample_predictions['Rzeczywista Warto≈õƒá'].map({0: 'Pora≈ºka', 1: 'Wygrana'})
        sample_predictions['Przewidywana Warto≈õƒá'] = sample_predictions['Przewidywana Warto≈õƒá'].map({0: 'Pora≈ºka', 1: 'Wygrana'})
        sample_predictions['Poprawno≈õƒá'] = sample_predictions['Poprawno≈õƒá'].map({0: 'B≈Çƒôdna', 1: 'Poprawna'})
        st.dataframe(sample_predictions, use_container_width=True)
        
        # Analiza dok≈Çadno≈õci
        st.subheader("Analiza Dok≈Çadno≈õci Predykcji")
        tn, fp, fn, tp = cm.ravel()
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Porawne Negatywy (TN)", int(tn))
        with col2:
            st.metric("B≈Çƒôdne Pozytywy (FP)", int(fp))
        with col3:
            st.metric("B≈Çƒôdne Negatywy (FN)", int(fn))
        with col4:
            st.metric("Porawne Pozytywy (TP)", int(tp))
        
        accuracy_details = pd.DataFrame({
            'Metrika': ['Czu≈Ço≈õƒá (Recall)', 'Specyficzno≈õƒá', 'Precyzja Dodatnia', 'Precyzja Ujemna'],
            'Warto≈õƒá': [
                f"{tp / (tp + fn):.3f}" if (tp + fn) > 0 else "N/A",
                f"{tn / (tn + fp):.3f}" if (tn + fp) > 0 else "N/A",
                f"{tp / (tp + fp):.3f}" if (tp + fp) > 0 else "N/A",
                f"{tn / (tn + fn):.3f}" if (tn + fn) > 0 else "N/A"
            ]
        })
        st.dataframe(accuracy_details, use_container_width=True)
        
        # Opis modelu
        descriptions = {
            'Logistic Regression': """
            **Charakterystyka:**
            - Model liniowy, interpretowalne wsp√≥≈Çczynniki
            - Zak≈Çada liniowƒÖ separowalno≈õƒá klas
            - Wra≈ºliwy na skalƒô zmiennych (zastosowali≈õmy StandardScaler)
            
            **Mocne strony:** Szybki, interpretowalne wyniki
            **S≈Çabe strony:** Mo≈ºe niedostatecznie uchwyciƒá interakcje
            """,
            'SVM (kernel RBF)': """
            **Charakterystyka:**
            - Kernel RBF umo≈ºliwia nieliniowƒÖ separacjƒô
            - Mapuje dane na wy≈ºszƒÖ przestrze≈Ñ wymiar√≥w
            - Wra≈ºliwy na skalƒô i outliery
            
            **Mocne strony:** Potƒô≈ºny dla z≈Ço≈ºonych granic decyzji
            **S≈Çabe strony:** Trudny do interpretacji, wymaga tuningu
            """,
            'Decision Tree': """
            **Charakterystyka:**
            - Hierarchiczna struktura decyzji
            - Niezmienny na skalƒô zmiennych
            - Podatny na overfitting
            
            **Mocne strony:** Wysoce interpretowalne, odporny na outliery
            **S≈Çabe strony:** Podatny na przeuczenie
            """,
            'Random Forest': """
            **Charakterystyka:**
            - Ensemble drzew decyzyjnych
            - Zmniejsza overfitting poprzez aggregacjƒô
            - Mniej wra≈ºliwy na outliery
            
            **Mocne strony:** Wysoka dok≈Çadno≈õƒá, zmniejszony overfitting
            **S≈Çabe strony:** Mniej interpretowalne ni≈º pojedyncze drzewo
            """
        }
        
        st.info(descriptions.get(model_name, ""))
    
    return pd.DataFrame(results), model_objects, cms, y_preds


def compare_models(results_df):
    """Por√≥wnanie modeli."""
    st.header("Czƒô≈õƒá 5: Por√≥wnanie Modeli")
    
    st.write("""
    Por√≥wnanie All modeli na podstawie kluczowych metryk klasyfikacji.
    """)
    
    # Tabela por√≥wnawcza
    st.subheader("Tabela Metryk")
    st.dataframe(results_df.round(3), use_container_width=True)
    
    # Wykresy por√≥wnawcze
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.bar(
            results_df,
            x='Model',
            y='Accuracy Test',
            title='Accuracy na zbiorze testowym',
            color='Accuracy Test',
            color_continuous_scale='Viridis'
        )
        fig.update_layout(xaxis={'tickangle': -45})
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = px.bar(
            results_df,
            x='Model',
            y='F1-Score',
            title='F1-Score (≈õrednia harmoniczna)',
            color='F1-Score',
            color_continuous_scale='Plasma'
        )
        fig.update_layout(xaxis={'tickangle': -45})
        st.plotly_chart(fig, use_container_width=True)
    
    # Radar chart
    st.subheader("Profil Modeli (Radar Chart)")
    
    fig = go.Figure()
    
    for idx, row in results_df.iterrows():
        fig.add_trace(go.Scatterpolar(
            r=[
                row['Accuracy Test'],
                row['Precision'],
                row['Recall'],
                row['F1-Score']
            ],
            theta=['Accuracy', 'Precision', 'Recall', 'F1-Score'],
            fill='toself',
            name=row['Model']
        ))
    
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=True,
        title='Profil Modeli'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Wybranie najlepszego modelu
    best_model_idx = results_df['F1-Score'].idxmax()
    best_model_name = results_df.loc[best_model_idx, 'Model']
    best_f1 = results_df.loc[best_model_idx, 'F1-Score']
    
    st.success(f"""
    **Najlepszy model: {best_model_name}**
    - F1-Score: {best_f1:.3f}
    - Accuracy: {results_df.loc[best_model_idx, 'Accuracy Test']:.3f}
    - Precision: {results_df.loc[best_model_idx, 'Precision']:.3f}
    - Recall: {results_df.loc[best_model_idx, 'Recall']:.3f}
    
    Wybrali≈õmy model na podstawie F1-Score, poniewa≈º uwzglƒôdnia zar√≥wno precyzjƒô jak i recall,
    kt√≥re sƒÖ r√≥wnie wa≈ºne dla tego problemu klasyfikacji.
    """)
    
    st.info("""
    **Analiza Wynik√≥w:**
    - Wszystkie modele osiƒÖgajƒÖ por√≥wnywalne wyniki (~70% accuracy)
    - Random Forest pokazuje najwiƒôkszƒÖ stabilno≈õƒá (najmniejszy overfitting)
    - Logistic Regression ma wysokƒÖ interpretowlan%, ale mo≈ºe brakowaƒá mu zdolno≈õci do 
      uchwycenia nieliniowych zale≈ºno≈õci
    - SVM i Random Forest wykazujƒÖ podobnƒÖ wydajno≈õƒá
    """)
    
    return best_model_name


def interpretability_section(model_objects, X_train, X_test, best_model_name):
    """Sekcja interpretowalno≈õci."""
    st.header("Czƒô≈õƒá 6: Analiza Interpretowalno≈õci")
    
    st.write("""
    Analiza wp≈Çywu zmiennych na predykcje modelu. Wykorzystujemy warto≈õci SHAP
    do znalezienia najwa≈ºniejszych cech.
    """)
    
    best_model = model_objects[best_model_name]
    
    st.subheader(f"Analiza modelu: {best_model_name}")
    
    # Feature Importance (dla modeli, kt√≥re to obs≈ÇugujƒÖ)
    if hasattr(best_model.named_steps['model'], 'feature_importances_'):
        st.write("**Feature Importance - wagi zmiennych:**")
        
        feature_importance = best_model.named_steps['model'].feature_importances_
        
        # Pobierz nazwy cech po preprocessingu
        X_test_transformed = best_model.named_steps['preprocessor'].transform(X_test)
        
        # Je≈õli masz nazwy cech, mo≈ºesz je tutaj wstawiƒá
        feature_names = [f"Feature_{i}" for i in range(len(feature_importance))]
        
        imp_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': feature_importance
        }).sort_values('Importance', ascending=False).head(15)
        
        fig = px.bar(
            imp_df,
            x='Importance',
            y='Feature',
            orientation='h',
            title='Top 15 Wa≈ºnych Zmiennych',
            color='Importance',
            color_continuous_scale='Viridis'
        )
        st.plotly_chart(fig, use_container_width=True)
    
    st.info("""
    **Wnioski z interpretowalnos**:
    - Top zmienne reprezentujƒÖ r√≥≈ºnice w liczbie zab√≥jstw, wie operacyjnych i szybko≈õci gromadzenia zasob√≥w
    - Te cechy intuicyjnie wp≈ÇywajƒÖ na wynik meczu
    - R√≥≈ºnice we wczesnej fazie (15. minuta) ju≈º mogƒÖ sugerowaƒá ostateczny wynik
    - Zmienne takie jak 'kills_diff', 'gold_diff' sƒÖ kluczowe dla zwyciƒôstwa
    """)


def summary_section(results_df, best_model_name):
    """Sekcja podsumowania."""
    st.header("Czƒô≈õƒá 7: Podsumowanie i Wnioski")
    
    st.write("""
    Kompletne podsumowanie ca≈Çego projektu analizy i modelowania danych.
    """)
    
    st.subheader("Streszczenie Etap√≥w Projektu")
    
    st.markdown("""
    **1. Eksploracyjna Analiza Danych (EDA)**
    - Przeanalizowali≈õmy 1953 obserwacje mecz√≥w League of Legends
    - Zidentyfikowali≈õmy 25 zmiennych reprezentujƒÖcych statystyki na 15. minucie
    - Potwierdzili≈õmy kompletno≈õƒá danych (brak brak√≥w)
    
    **2. Przygotowanie Danych**
    - Zidentyfikowali≈õmy warto≈õci odstajƒÖce, ale je zachowali≈õmy (naturalne dla gier)
    - Zastosowali≈õmy StandardScaler dla zmiennych numerycznych
    - One-Hot Encoding dla zmiennych kategorycznych
    
    **3. Podzia≈Ç Train/Test**
    - 70% danych treningowych, 30% testowych (stratified split)
    - Zachowano balans klas w obu zbiorach
    - Random state = 42 dla powtarzalno≈õci
    
    **4. Modele Klasyfikacji**
    - Logistic Regression: model liniowy, szybki
    - SVM (kernel RBF): model nieliniowy
    - Decision Tree: model interpretowdalny
    - Random Forest: ensemble dla wy≈ºszej dok≈Çadno≈õci
    
    **5. Por√≥wnanie Modeli**
    - Wszystkie modele osiƒÖgnƒô≈Çy ~70% accuracy
    - F1-Score u≈ºyty jako g≈Ç√≥wna metrika
    """)
    
    st.subheader("Kluczowe Wyniki")
    
    best_f1 = results_df.loc[results_df['Model'] == best_model_name, 'F1-Score'].values[0]
    best_acc = results_df.loc[results_df['Model'] == best_model_name, 'Accuracy Test'].values[0]
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Najlepszy Model", best_model_name)
    with col2:
        st.metric("Accuracy", f"{best_acc:.3f}")
    with col3:
        st.metric("F1-Score", f"{best_f1:.3f}")
    
    st.subheader("Wnioski Ko≈Ñcowe")
    
    st.success(f"""
    **Model: {best_model_name}**
    
    Zdolno≈õƒá predykcji wyniku meczu na podstawie statystyk z 15. minuty wynosi ~{best_acc*100:.1f}%.
    Model jest wystarczajƒÖco dok≈Çadny do praktycznego zastosowania w analizie mecz√≥w.
    """)
    
    st.info("""
    **Ograniczenia Analizy:**
    - Dane pochodzƒÖ tylko z dywizji GOLD
    - Uwzglƒôdniamy tylko pierwsze 15 minut meczu
    - Brakuje informacji o wyborze postaci i itemach
    - Mo≈ºliwe ukryte zmienne wp≈ÇywajƒÖce na wynik
    
    **Mo≈ºliwe Kierunki Dalszego Rozwoju:**
    1. **Tuning Hiperparametr√≥w**: GridSearchCV, RandomizedSearchCV
    2. **Feature Engineering**: kombinacje zmiennych, pochodne
    3. **Inne Algorytmy**: Gradient Boosting, Neural Networks
    4. **Cross-Validation**: K-fold CV dla bardziej stabilnych ocen
    5. **Class Imbalance**: SMOTE je≈õli by≈Çby problem z niezbalansowaniem
    6. **Rekalibracja**: Probability Calibration dla lepszych prawdopodobie≈Ñstw
    7. **Analiza SHAP**: Szczeg√≥≈Çowa analiza wp≈Çywu zmiennych
    8. **R√≥≈ºne Dywizje**: Trenowanie oddzielnych modeli dla ka≈ºdej dywizji
    """)
    
    st.markdown("---")
    st.write("**Koniec projektu analizy i modelowania danych Liga of Legends**")
    st.write("Projekt zawiera wszystkie etapy: EDA ‚Üí Preprocessing ‚Üí Modelowanie ‚Üí Ocena ‚Üí Interpretacja")


def main():
    """G≈Ç√≥wna funkcja aplikacji."""
    
    st.title("League of Legends - Kompletny Pipeline Analizy i ML")
    
    st.markdown("""
    ### Projekt Analizy i Modelowania Danych
    
    Aplikacja zawiera kompletny pipeline:
    - Eksploracyjna Analiza Danych (EDA)
    - Przygotowanie Danych
    - Podzia≈Ç Train/Test
    - Modele Machine Learning (4 algorytmy)
    - Por√≥wnanie Modeli
    - Analiza Interpretowalno≈õci
    - Wnioski
    
    **Autorzy:** Kamil ≈Åadyga, Mi≈Çosz Polinceusz
    """)
    
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.header("Konfiguracja")
        
        data_path = st.text_input(
            "≈öcie≈ºka do danych:",
            value="data/output/gold_dataset.csv"
        )
        
        st.markdown("---")
        st.header("Nawigacja")
        st.markdown("""
        1. Eksploracyjna Analiza Danych
        2. Przygotowanie Danych
        3. Podzia≈Ç Train/Test
        4. Modele Machine Learning
        5. Por√≥wnanie Modeli
        6. Analiza Interpretowalno≈õci
        7. Podsumowanie
        """)
    
    # Wczytaj dane
    df = load_data(data_path)
    
    if df is None:
        st.stop()
    
    # Sekcje aplikacji
    eda_section(df)
    st.markdown("---")
    
    numeric_cols, categorical_cols = data_preparation(df)
    st.markdown("---")
    
    X_train, X_test, y_train, y_test, X = train_test_split_section(df)
    st.markdown("---")
    
    results_df, model_objects, cms, y_preds = ml_models_section(X_train, X_test, y_train, y_test, X)
    st.markdown("---")
    
    best_model_name = compare_models(results_df)
    st.markdown("---")
    
    interpretability_section(model_objects, X_train, X_test, best_model_name)
    st.markdown("---")
    
    summary_section(results_df, best_model_name)


if __name__ == "__main__":
    main()
