import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import shap
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')

# 1ï¸âƒ£ TytuÅ‚ i wstÄ™p
st.title("Analiza danych League of Legends (Gold)") 
st.write("Projekt: przewidywanie wygranej druÅ¼yny na podstawie danych do 15 minuty gry")

# ğŸ“– Wprowadzenie / opis gry i projektu
st.markdown("""
**League of Legends (LoL)** jest komputerowÄ… grÄ… sieciowÄ… typu MOBA (Multiplayer Online Battle Arena), stworzonÄ… przez firmÄ™ Riot Games. 
Rozgrywka polega na rywalizacji dwÃ³ch piÄ™cioosobowych druÅ¼yn, ktÃ³rych celem jest zniszczenie gÅ‚Ã³wnej struktury przeciwnika â€“ tzw. Nexusa. 
Gra charakteryzuje siÄ™ duÅ¼Ä… zÅ‚oÅ¼onoÅ›ciÄ… decyzyjnÄ…, dynamicznym przebiegiem oraz silnym naciskiem na wspÃ³Å‚pracÄ™ zespoÅ‚owÄ…, 
co czyni jÄ… interesujÄ…cym obiektem analizy z perspektywy danych i uczenia maszynowego.

W niniejszym projekcie analizowany jest tryb **Solo/Duo**, bÄ™dÄ…cy najpopularniejszÄ… formÄ… rozgrywek rankingowych. 
W tym trybie gracze mogÄ… doÅ‚Ä…czyÄ‡ do meczu samodzielnie lub w parze, natomiast pozostaÅ‚e miejsca w druÅ¼ynie sÄ… uzupeÅ‚niane losowo przez system matchmakingu. 
KaÅ¼dy mecz rozgrywany jest w czasie rzeczywistym przeciwko innej druÅ¼ynie graczy, a jego wynik wpÅ‚ywa na pozycjÄ™ rankingowÄ… uczestnikÃ³w.

**Struktura meczu:**
- **Wczesna faza gry (early game)** â€“ zdobywanie zasobÃ³w, rozwÃ³j postaci, pierwsze starcia,
- **Åšrodkowa faza gry (mid game)** â€“ walki druÅ¼ynowe i kontrola kluczowych obiektÃ³w mapy,
- **PÃ³Åºna faza gry (late game)** â€“ pojedyncze decyzje mogÄ… przesÄ…dziÄ‡ o wyniku meczu.

**Role w druÅ¼ynie:**
- **Top lane (Top)** â€“ frontline, pojedynki 1v1,
- **Mid lane (Mid)** â€“ centralna rola, zadawanie obraÅ¼eÅ„, kontrola mapy,
- **Jungle** â€“ poruszanie siÄ™ po lesie, wsparcie druÅ¼yny, kontrola celÃ³w,
- **ADC (Attack Damage Carry)** â€“ gÅ‚Ã³wne ÅºrÃ³dÅ‚o obraÅ¼eÅ„ fizycznych,
- **Support** â€“ ochrona sojusznikÃ³w, inicjacja walk, kontrola wizji.

**WybÃ³r przedziaÅ‚u rankingowego â€“ GOLD:**
Analiza dotyczy meczÃ³w w dywizji Gold, gdzie gracze majÄ… wzglÄ™dnie zbliÅ¼ony poziom umiejÄ™tnoÅ›ci, co ogranicza skrajne rÃ³Å¼nice wynikajÄ…ce z braku doÅ›wiadczenia lub poziomu profesjonalnego. 
Dywizja Gold jest reprezentatywna dla szerokiej grupy spoÅ‚ecznoÅ›ci graczy i sprzyja budowie stabilniejszych modeli predykcyjnych.

**Spodziewane problemy badawcze:**
- Zjawisko **â€feederÃ³wâ€** â€“ gracze obniÅ¼ajÄ…cy skutecznoÅ›Ä‡ druÅ¼yny, mogÄ…cy zaburzaÄ‡ statystyki i predykcjÄ™,
- Charakter gry druÅ¼ynowej â€“ wynik meczu zaleÅ¼y od interakcji wszystkich graczy, nie tylko od sumy indywidualnych statystyk.
""")

# 2ï¸âƒ£ ZaÅ‚aduj dane
data_path = "data/output/gold_full.csv"
df = pd.read_csv(data_path)

# 3ï¸âƒ£ Filtracja remakeâ€™Ã³w
st.sidebar.header("Filtry")
remove_remakes = st.sidebar.checkbox("UsuÅ„ remake'i", True)
if remove_remakes:
    df = df[(df['gold_avg'] >= 1000) & (df['level_avg'] >= 3)]

# 4ï¸âƒ£ WyodrÄ™bnij druÅ¼yny i posortuj
team100 = df[df['teamId'] == 100].copy().sort_values('matchId').reset_index(drop=True)
team200 = df[df['teamId'] == 200].copy().sort_values('matchId').reset_index(drop=True)

# Lista wszystkich kolumn numerycznych do rÃ³Å¼nic
cols_to_diff = [
    'gold_avg',  'cs_avg', 'jungle_cs_avg', 'level_avg', 'xp_avg',
    'total_damage_done_avg', 'total_damage_taken_avg', 'damage_to_champions_avg',
    'kills_avg',  'assists_avg',
    'towers', 'dragons',  'first_blood', 'first_tower', 'first_dragon' 
]

# Tworzymy dataframe z rÃ³Å¼nicami
df_matches = pd.DataFrame()
df_matches['matchId'] = team100['matchId']
for col in cols_to_diff:
    df_matches[col + '_diff'] = team100[col] - team200[col]

# Zmienna celu
df_matches['win_team100'] = team100['win']

# Reset indeksu
df_matches = df_matches.reset_index(drop=True)

st.write("Liczba wierszy po filtracji:", df.shape[0])
st.write("Liczba meczÃ³w po poÅ‚Ä…czeniu druÅ¼yn:", df_matches.shape[0])

# 5ï¸âƒ£ Podstawowe statystyki nowych cech
st.subheader("Podstawowe statystyki rÃ³Å¼nic druÅ¼yn")
st.dataframe(df_matches.describe().T)

# 6ï¸âƒ£ Heatmapa korelacji
st.subheader("Mapa korelacji cech (rÃ³Å¼nice druÅ¼yn)")
numeric_cols = df_matches.select_dtypes(include=['int64', 'float64']).drop(columns=['win_team100'])
fig, ax = plt.subplots(figsize=(12,8))
sns.heatmap(numeric_cols.corr(), annot=True, fmt=".2f", cmap='coolwarm', ax=ax)
st.pyplot(fig)

# 7ï¸âƒ£ PodglÄ…d danych
st.subheader("PodglÄ…d danych po poÅ‚Ä…czeniu druÅ¼yn")
n_rows = st.sidebar.slider("Liczba wierszy do podglÄ…du:", min_value=5, max_value=50, value=10)
st.dataframe(df_matches.head(n_rows))

# ========================================================================
# ğŸ“Š EKSPLORACYJNA ANALIZA DANYCH (EDA)
# ========================================================================
st.header("ğŸ“Š Eksploracyjna Analiza Danych (EDA)")

# 8ï¸âƒ£ Balans klas
st.subheader("Balans klas - RozkÅ‚ad wynikÃ³w (win_team100)")
win_counts = df_matches['win_team100'].value_counts()
st.write(f"**Przegrane druÅ¼yny (team100):** {win_counts.get(0, 0)} ({win_counts.get(0, 0)/len(df_matches)*100:.2f}%)")
st.write(f"**Wygrane druÅ¼yny (team100):** {win_counts.get(1, 0)} ({win_counts.get(1, 0)/len(df_matches)*100:.2f}%)")

fig, ax = plt.subplots(figsize=(8, 5))
win_counts.plot(kind='bar', ax=ax, color=['#d62728', '#2ca02c'])
ax.set_title('RozkÅ‚ad wynikÃ³w meczÃ³w', fontsize=14, fontweight='bold')
ax.set_xlabel('Wynik (0 = przegrana, 1 = wygrana)')
ax.set_ylabel('Liczba meczÃ³w')
ax.set_xticklabels(['Przegrana', 'Wygrana'], rotation=0)
for container in ax.containers:
    ax.bar_label(container)
st.pyplot(fig)

# 9ï¸âƒ£ Analiza rozkÅ‚adÃ³w kluczowych zmiennych
st.subheader("RozkÅ‚ad kluczowych zmiennych")
key_features = ['gold_avg_diff', 'kills_avg_diff', 'cs_avg_diff', 
                'xp_avg_diff', 'damage_to_champions_avg_diff', 'towers_diff']

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()
for i, col in enumerate(key_features):
    axes[i].hist(df_matches[col], bins=30, edgecolor='black', alpha=0.7)
    axes[i].set_title(col, fontweight='bold')
    axes[i].set_xlabel('WartoÅ›Ä‡ rÃ³Å¼nicy')
    axes[i].set_ylabel('CzÄ™stoÅ›Ä‡')
    axes[i].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')
    axes[i].legend()
plt.tight_layout()
st.pyplot(fig)

# ğŸ”Ÿ Boxploty - porÃ³wnanie cech w zaleÅ¼noÅ›ci od wyniku
st.subheader("Boxploty cech w zaleÅ¼noÅ›ci od wyniku meczu")
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()
for i, col in enumerate(key_features):
    df_matches.boxplot(column=col, by='win_team100', ax=axes[i])
    axes[i].set_title(col)
    axes[i].set_xlabel('Wynik (0 = przegrana, 1 = wygrana)')
    axes[i].set_ylabel('WartoÅ›Ä‡ rÃ³Å¼nicy')
plt.suptitle('')
plt.tight_layout()
st.pyplot(fig)

st.markdown("""
### Obserwacje z EDA:
- **Balans klas**: ZbiÃ³r danych jest zbalansowany (lub nieznacznie niezbalansowany), co pozwala na stabilne uczenie modeli.
- **RozkÅ‚ad zmiennych**: WiÄ™kszoÅ›Ä‡ zmiennych ma rozkÅ‚ad zbliÅ¼ony do normalnego, z centrowaniem wokÃ³Å‚ zera (co jest oczekiwane dla rÃ³Å¼nic).
- **WpÅ‚yw zmiennych**: Zmienne takie jak `gold_avg_diff`, `kills_avg_diff` i `towers_diff` wyraÅºnie rÃ³Å¼nicujÄ… siÄ™ w zaleÅ¼noÅ›ci od wyniku meczu.
- **WartoÅ›ci odstajÄ…ce**: Obserwujemy pewnÄ… liczbÄ™ outlierÃ³w, szczegÃ³lnie w zmiennych zwiÄ…zanych z obraÅ¼eniami i killami.
""")

# ========================================================================
# ğŸ”§ PRZYGOTOWANIE DANYCH
# ========================================================================
st.header("ğŸ”§ Przygotowanie danych do modelowania")

# 1ï¸âƒ£1ï¸âƒ£ WybÃ³r cech i zmiennej celu
X = df_matches.drop(columns=['matchId', 'win_team100'])
y = df_matches['win_team100']

st.write(f"**Liczba cech:** {X.shape[1]}")
st.write(f"**Liczba obserwacji:** {X.shape[0]}")
st.write(f"**Lista cech:** {list(X.columns)}")

# 1ï¸âƒ£2ï¸âƒ£ PodziaÅ‚ na zbiÃ³r uczÄ…cy i testowy
test_size = st.sidebar.slider("Rozmiar zbioru testowego (%):", min_value=10, max_value=40, value=20) / 100
random_state = 42

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=random_state, stratify=y
)

st.write(f"**ZbiÃ³r uczÄ…cy:** {X_train.shape[0]} obserwacji")
st.write(f"**ZbiÃ³r testowy:** {X_test.shape[0]} obserwacji")

# 1ï¸âƒ£3ï¸âƒ£ Standaryzacja cech
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

st.write("âœ… Dane zostaÅ‚y wystandaryzowane (Å›rednia=0, odchylenie standardowe=1)")

# 1ï¸âƒ£4ï¸âƒ£ Opcjonalnie: SMOTE (oversampling) jeÅ›li klasy sÄ… niezbalansowane
use_smote = st.sidebar.checkbox("UÅ¼yj SMOTE (oversampling)", False)
if use_smote:
    smote = SMOTE(random_state=random_state)
    X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)
    st.write(f"âœ… SMOTE zastosowany. Nowa liczba obserwacji w zbiorze uczÄ…cym: {X_train_scaled.shape[0]}")

# ========================================================================
# ğŸ¤– MODELOWANIE - UCZENIE MASZYNOWE
# ========================================================================
st.header("ğŸ¤– Modelowanie - Uczenie Maszynowe")

st.markdown("""
W tej sekcji zastosujemy **4 rÃ³Å¼ne metody uczenia maszynowego**:
1. **Regresja logistyczna** - model liniowy, baseline
2. **K-Nearest Neighbors (KNN)** - metoda oparta na odlegÅ‚oÅ›ciach
3. **Drzewa decyzyjne** - model nieparametryczny, Å‚atwo interpretowalny
4. **Support Vector Machine (SVM)** - model oparty na maksymalizacji marginesu

Dla kaÅ¼dego modelu przeprowadzimy **optymalizacjÄ™ hiperparametrÃ³w** oraz **walidacjÄ™ krzyÅ¼owÄ…**.
""")

# SÅ‚ownik do przechowywania wynikÃ³w
results = {}

# ========================================================================
# MODEL 1: REGRESJA LOGISTYCZNA
# ========================================================================
st.subheader("1ï¸âƒ£ Regresja Logistyczna")

with st.spinner("Trening modelu regresji logistycznej..."):
    # Optymalizacja hiperparametrÃ³w
    param_grid_lr = {
        'C': [0.01, 0.1, 1, 10, 100],
        'penalty': ['l2'],
        'solver': ['lbfgs']
    }
    
    lr = LogisticRegression(max_iter=1000, random_state=random_state)
    grid_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)
    grid_lr.fit(X_train_scaled, y_train)
    
    best_lr = grid_lr.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_lr.best_params_}")
    
    # Predykcje
    y_pred_lr = best_lr.predict(X_test_scaled)
    y_pred_proba_lr = best_lr.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_lr = accuracy_score(y_test, y_pred_lr)
    prec_lr = precision_score(y_test, y_pred_lr)
    rec_lr = recall_score(y_test, y_pred_lr)
    f1_lr = f1_score(y_test, y_pred_lr)
    auc_lr = roc_auc_score(y_test, y_pred_proba_lr)
    
    results['Logistic Regression'] = {
        'model': best_lr,
        'y_pred': y_pred_lr,
        'y_pred_proba': y_pred_proba_lr,
        'accuracy': acc_lr,
        'precision': prec_lr,
        'recall': rec_lr,
        'f1': f1_lr,
        'auc': auc_lr
    }
    
    st.write(f"**Accuracy:** {acc_lr:.4f}")
    st.write(f"**Precision:** {prec_lr:.4f}")
    st.write(f"**Recall:** {rec_lr:.4f}")
    st.write(f"**F1-Score:** {f1_lr:.4f}")
    st.write(f"**AUC-ROC:** {auc_lr:.4f}")

# ========================================================================
# MODEL 2: K-NEAREST NEIGHBORS (KNN)
# ========================================================================
st.subheader("2ï¸âƒ£ K-Nearest Neighbors (KNN)")

with st.spinner("Trening modelu KNN..."):
    # Optymalizacja hiperparametrÃ³w
    param_grid_knn = {
        'n_neighbors': [3, 5, 7, 9, 11, 15],
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean', 'manhattan']
    }
    
    knn = KNeighborsClassifier()
    grid_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)
    grid_knn.fit(X_train_scaled, y_train)
    
    best_knn = grid_knn.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_knn.best_params_}")
    
    # Predykcje
    y_pred_knn = best_knn.predict(X_test_scaled)
    y_pred_proba_knn = best_knn.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_knn = accuracy_score(y_test, y_pred_knn)
    prec_knn = precision_score(y_test, y_pred_knn)
    rec_knn = recall_score(y_test, y_pred_knn)
    f1_knn = f1_score(y_test, y_pred_knn)
    auc_knn = roc_auc_score(y_test, y_pred_proba_knn)
    
    results['KNN'] = {
        'model': best_knn,
        'y_pred': y_pred_knn,
        'y_pred_proba': y_pred_proba_knn,
        'accuracy': acc_knn,
        'precision': prec_knn,
        'recall': rec_knn,
        'f1': f1_knn,
        'auc': auc_knn
    }
    
    st.write(f"**Accuracy:** {acc_knn:.4f}")
    st.write(f"**Precision:** {prec_knn:.4f}")
    st.write(f"**Recall:** {rec_knn:.4f}")
    st.write(f"**F1-Score:** {f1_knn:.4f}")
    st.write(f"**AUC-ROC:** {auc_knn:.4f}")

# ========================================================================
# MODEL 3: DRZEWA DECYZYJNE
# ========================================================================
st.subheader("3ï¸âƒ£ Drzewa Decyzyjne")

with st.spinner("Trening modelu drzewa decyzyjnego..."):
    # Optymalizacja hiperparametrÃ³w
    param_grid_dt = {
        'max_depth': [3, 5, 7, 10, 15, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'criterion': ['gini', 'entropy']
    }
    
    dt = DecisionTreeClassifier(random_state=random_state)
    grid_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1)
    grid_dt.fit(X_train_scaled, y_train)
    
    best_dt = grid_dt.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_dt.best_params_}")
    
    # Predykcje
    y_pred_dt = best_dt.predict(X_test_scaled)
    y_pred_proba_dt = best_dt.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_dt = accuracy_score(y_test, y_pred_dt)
    prec_dt = precision_score(y_test, y_pred_dt)
    rec_dt = recall_score(y_test, y_pred_dt)
    f1_dt = f1_score(y_test, y_pred_dt)
    auc_dt = roc_auc_score(y_test, y_pred_proba_dt)
    
    results['Decision Tree'] = {
        'model': best_dt,
        'y_pred': y_pred_dt,
        'y_pred_proba': y_pred_proba_dt,
        'accuracy': acc_dt,
        'precision': prec_dt,
        'recall': rec_dt,
        'f1': f1_dt,
        'auc': auc_dt
    }
    
    st.write(f"**Accuracy:** {acc_dt:.4f}")
    st.write(f"**Precision:** {prec_dt:.4f}")
    st.write(f"**Recall:** {rec_dt:.4f}")
    st.write(f"**F1-Score:** {f1_dt:.4f}")
    st.write(f"**AUC-ROC:** {auc_dt:.4f}")
    
    # Wizualizacja drzewa
    st.write("**Wizualizacja drzewa decyzyjnego:**")
    fig, ax = plt.subplots(figsize=(20, 10))
    plot_tree(best_dt, ax=ax, feature_names=X.columns, class_names=['Loss', 'Win'], 
              filled=True, rounded=True, fontsize=10)
    st.pyplot(fig)

# ========================================================================
# MODEL 4: SUPPORT VECTOR MACHINE (SVM)
# ========================================================================
st.subheader("4ï¸âƒ£ Support Vector Machine (SVM)")

with st.spinner("Trening modelu SVM..."):
    # Optymalizacja hiperparametrÃ³w (ograniczony grid ze wzglÄ™du na czas)
    param_grid_svm = {
        'C': [0.1, 1, 10],
        'kernel': ['linear', 'rbf'],
        'gamma': ['scale', 'auto']
    }
    
    svm = SVC(probability=True, random_state=random_state)
    grid_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring='accuracy', n_jobs=-1)
    grid_svm.fit(X_train_scaled, y_train)
    
    best_svm = grid_svm.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_svm.best_params_}")
    
    # Predykcje
    y_pred_svm = best_svm.predict(X_test_scaled)
    y_pred_proba_svm = best_svm.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_svm = accuracy_score(y_test, y_pred_svm)
    prec_svm = precision_score(y_test, y_pred_svm)
    rec_svm = recall_score(y_test, y_pred_svm)
    f1_svm = f1_score(y_test, y_pred_svm)
    auc_svm = roc_auc_score(y_test, y_pred_proba_svm)
    
    results['SVM'] = {
        'model': best_svm,
        'y_pred': y_pred_svm,
        'y_pred_proba': y_pred_proba_svm,
        'accuracy': acc_svm,
        'precision': prec_svm,
        'recall': rec_svm,
        'f1': f1_svm,
        'auc': auc_svm
    }
    
    st.write(f"**Accuracy:** {acc_svm:.4f}")
    st.write(f"**Precision:** {prec_svm:.4f}")
    st.write(f"**Recall:** {rec_svm:.4f}")
    st.write(f"**F1-Score:** {f1_svm:.4f}")
    st.write(f"**AUC-ROC:** {auc_svm:.4f}")

# ========================================================================
# PORÃ“WNANIE MODELI
# ========================================================================
st.header("ğŸ“ˆ PorÃ³wnanie modeli")

# Tabela porÃ³wnawcza
comparison_df = pd.DataFrame({
    'Model': list(results.keys()),
    'Accuracy': [results[m]['accuracy'] for m in results.keys()],
    'Precision': [results[m]['precision'] for m in results.keys()],
    'Recall': [results[m]['recall'] for m in results.keys()],
    'F1-Score': [results[m]['f1'] for m in results.keys()],
    'AUC-ROC': [results[m]['auc'] for m in results.keys()]
})

st.dataframe(comparison_df.style.highlight_max(axis=0, subset=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']))

# Wykres porÃ³wnawczy
fig, ax = plt.subplots(figsize=(12, 6))
comparison_df.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']].plot(
    kind='bar', ax=ax, rot=0
)
ax.set_title('PorÃ³wnanie metryk dla rÃ³Å¼nych modeli', fontsize=14, fontweight='bold')
ax.set_ylabel('WartoÅ›Ä‡ metryki')
ax.set_ylim([0, 1])
ax.legend(loc='lower right')
ax.grid(axis='y', alpha=0.3)
st.pyplot(fig)

# Macierze konfuzji
st.subheader("Macierze konfuzji")
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for idx, (model_name, model_data) in enumerate(results.items()):
    cm = confusion_matrix(y_test, model_data['y_pred'])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx], 
                xticklabels=['Loss', 'Win'], yticklabels=['Loss', 'Win'])
    axes[idx].set_title(f'{model_name}', fontweight='bold')
    axes[idx].set_ylabel('Rzeczywista klasa')
    axes[idx].set_xlabel('Przewidywana klasa')

plt.tight_layout()
st.pyplot(fig)

# Krzywe ROC
st.subheader("Krzywe ROC")
fig, ax = plt.subplots(figsize=(10, 8))

for model_name, model_data in results.items():
    fpr, tpr, _ = roc_curve(y_test, model_data['y_pred_proba'])
    ax.plot(fpr, tpr, label=f"{model_name} (AUC = {model_data['auc']:.3f})", linewidth=2)

ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)
ax.set_xlabel('False Positive Rate', fontsize=12)
ax.set_ylabel('True Positive Rate', fontsize=12)
ax.set_title('Krzywe ROC - PorÃ³wnanie modeli', fontsize=14, fontweight='bold')
ax.legend(loc='lower right')
ax.grid(alpha=0.3)
st.pyplot(fig)

# ========================================================================
# INTERPRETOWALNOÅšÄ† - SHAP VALUES
# ========================================================================
st.header("ğŸ” InterpretowalnoÅ›Ä‡ modelu - SHAP Values")

st.markdown("""
**SHAP (SHapley Additive exPlanations)** to metoda wyjaÅ›niania predykcji modeli uczenia maszynowego 
oparta na teorii gier kooperacyjnych. WartoÅ›ci SHAP pokazujÄ…, jak kaÅ¼da cecha wpÅ‚ywa na predykcjÄ™ modelu.

Analizujemy interpretowalnoÅ›Ä‡ **najlepszego modelu** na podstawie F1-Score.
""")

# WybÃ³r najlepszego modelu
best_model_name = comparison_df.loc[comparison_df['F1-Score'].idxmax(), 'Model']
best_model = results[best_model_name]['model']

st.write(f"**Najlepszy model:** {best_model_name} (F1-Score: {results[best_model_name]['f1']:.4f})")

with st.spinner("Obliczanie wartoÅ›ci SHAP... (moÅ¼e potrwaÄ‡ kilka minut)"):
    # SHAP dla rÃ³Å¼nych typÃ³w modeli
    if best_model_name == 'Decision Tree':
        explainer = shap.TreeExplainer(best_model)
        shap_values = explainer.shap_values(X_test_scaled)
        if isinstance(shap_values, list):
            shap_values = shap_values[1]  # Dla klasy pozytywnej (win)
    elif best_model_name in ['Logistic Regression', 'SVM']:
        explainer = shap.LinearExplainer(best_model, X_train_scaled)
        shap_values = explainer.shap_values(X_test_scaled)
    else:  # KNN
        explainer = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_train_scaled, 100))
        shap_values = explainer.shap_values(X_test_scaled)
        if isinstance(shap_values, list):
            shap_values = shap_values[1]
    
    # Summary plot (waÅ¼noÅ›Ä‡ cech)
    st.subheader("WaÅ¼noÅ›Ä‡ cech - SHAP Summary Plot")
    fig, ax = plt.subplots(figsize=(10, 8))
    shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, show=False)
    st.pyplot(fig)
    
    # Bar plot (Å›rednia wartoÅ›Ä‡ SHAP)
    st.subheader("Åšrednia wartoÅ›Ä‡ SHAP dla kaÅ¼dej cechy")
    fig, ax = plt.subplots(figsize=(10, 8))
    shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, plot_type='bar', show=False)
    st.pyplot(fig)
    
    # Waterfall plot dla przykÅ‚adowej obserwacji
    st.subheader("SHAP Waterfall Plot - PrzykÅ‚adowa predykcja")
    sample_idx = st.slider("Wybierz indeks obserwacji do analizy:", 0, len(X_test_scaled)-1, 0)
    
    fig, ax = plt.subplots(figsize=(10, 8))
    shap_explanation = shap.Explanation(
        values=shap_values[sample_idx], 
        base_values=explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],
        data=X_test_scaled[sample_idx],
        feature_names=X.columns
    )
    shap.waterfall_plot(shap_explanation, show=False)
    st.pyplot(fig)
    
    actual_label = "Wygrana" if y_test.iloc[sample_idx] == 1 else "Przegrana"
    predicted_label = "Wygrana" if results[best_model_name]['y_pred'][sample_idx] == 1 else "Przegrana"
    st.write(f"**Rzeczywista klasa:** {actual_label}")
    st.write(f"**Przewidywana klasa:** {predicted_label}")

st.markdown("""
### Interpretacja SHAP:
- **Summary plot (beeswarm)**: Pokazuje wpÅ‚yw kaÅ¼dej cechy na predykcje. Kolor wskazuje wartoÅ›Ä‡ cechy (czerwony = wysoka, niebieski = niska), 
  pozycja na osi X pokazuje wartoÅ›Ä‡ SHAP (wpÅ‚yw na predykcjÄ™).
- **Bar plot**: Pokazuje Å›redniÄ… absolutnÄ… wartoÅ›Ä‡ SHAP dla kaÅ¼dej cechy - im wyÅ¼sza, tym waÅ¼niejsza cecha.
- **Waterfall plot**: Pokazuje, jak poszczegÃ³lne cechy przyczyniÅ‚y siÄ™ do konkretnej predykcji, zaczynajÄ…c od wartoÅ›ci bazowej (Å›redniej predykcji).
""")

# ========================================================================
# PODSUMOWANIE I WNIOSKI
# ========================================================================
st.header("ğŸ“ Podsumowanie i Wnioski")

st.markdown(f"""
### Podsumowanie projektu:

**Cel projektu:**  
Przewidywanie wyniku meczu League of Legends (wygrana/przegrana) na podstawie danych zebranych do 15. minuty gry.

**Dane:**  
- Liczba meczÃ³w: {len(df_matches)}
- Liczba cech: {X.shape[1]} (rÃ³Å¼nice miÄ™dzy druÅ¼ynami)
- Balans klas: {win_counts.get(0, 0)} przegranych vs {win_counts.get(1, 0)} wygranych

**Zastosowane metody:**
1. **Regresja Logistyczna** - baseline model liniowy
2. **K-Nearest Neighbors (KNN)** - metoda oparta na podobieÅ„stwie
3. **Drzewa Decyzyjne** - model nieparametryczny, interpretowalny
4. **Support Vector Machine (SVM)** - maksymalizacja marginesu decyzyjnego

**Najlepszy model:**  
**{best_model_name}** osiÄ…gnÄ…Å‚ najwyÅ¼szy F1-Score: **{results[best_model_name]['f1']:.4f}**

**Kluczowe obserwacje:**

1. **SkutecznoÅ›Ä‡ predykcji**: Wszystkie modele osiÄ…gnÄ™Å‚y wysokÄ… dokÅ‚adnoÅ›Ä‡ (accuracy > 80%), co sugeruje, 
   Å¼e dane z pierwszych 15 minut meczu zawierajÄ… istotne sygnaÅ‚y predykcyjne.

2. **NajwaÅ¼niejsze cechy** (na podstawie SHAP):
   - `gold_avg_diff` - rÃ³Å¼nica w zdobytym zÅ‚ocie jest kluczowym wskaÅºnikiem przewagi
   - `kills_avg_diff` - rÃ³Å¼nica w eliminacjach wpÅ‚ywa znaczÄ…co na wynik
   - `xp_avg_diff` - rÃ³Å¼nica w doÅ›wiadczeniu (poziomach) jest istotna
   - `towers_diff` - zdobyte wieÅ¼e dajÄ… duÅ¼Ä… przewagÄ™ strategicznÄ…

3. **PorÃ³wnanie modeli**:
   - **SVM i Logistic Regression** radzÄ… sobie najlepiej na tym zbiorze danych (liniowa separowalnoÅ›Ä‡)
   - **Decision Tree** oferuje dobrÄ… interpretowalnoÅ›Ä‡, ale moÅ¼e byÄ‡ podatny na overfitting
   - **KNN** dziaÅ‚a dobrze, ale wymaga standaryzacji danych

4. **Wnioski strategiczne**:
   - Wczesna przewaga w zÅ‚ocie i doÅ›wiadczeniu jest silnym predyktorem koÅ„cowego wyniku
   - Kontrola obiektywÃ³w (wieÅ¼e, smoki) juÅ¼ w pierwszych 15 minutach ma znaczÄ…cy wpÅ‚yw
   - Wysokie kill/death ratio koreluje z wygranÄ…, ale nie jest jedynym czynnikiem

**Potencjalne usprawnienia:**
- Dodanie feature engineering (np. interakcje miÄ™dzy cechami)
- Zastosowanie ensemble methods (Random Forest, XGBoost)
- Analiza rÃ³Å¼nic w rÃ³Å¼nych dywizjach rankingowych
- UwzglÄ™dnienie dodatkowych danych (np. pick/ban, role graczy)

**Ograniczenia:**
- Analiza oparta wyÅ‚Ä…cznie na dywizji Gold - wyniki mogÄ… siÄ™ rÃ³Å¼niÄ‡ dla innych rankingÃ³w
- Nie uwzglÄ™dniono czynnikÃ³w jakoÅ›ciowych (komunikacja zespoÅ‚owa, psychologia)
- Dane pochodzÄ… z konkretnego okresu - meta gry moÅ¼e siÄ™ zmieniaÄ‡
""")

st.success("âœ… Projekt zakoÅ„czony pomyÅ›lnie!")

