import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import shap
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')


# TytuÅ‚ i wstÄ™p
st.title("Analiza danych League of Legends z dywizji Gold") 
st.write("Projekt: przewidywanie wygranej druÅ¼yny na podstawie danych do 15 minuty gry")

# Wprowadzenie / opis gry i projektu
st.markdown("""
**League of Legends (LoL)** jest komputerowÄ… grÄ… sieciowÄ… typu MOBA (Multiplayer Online Battle Arena), stworzonÄ… przez firmÄ™ Riot Games. 
Rozgrywka polega na rywalizacji dwÃ³ch piÄ™cioosobowych druÅ¼yn, ktÃ³rych celem jest zniszczenie gÅ‚Ã³wnej struktury przeciwnika â€“ tzw. Nexusa. 
Gra charakteryzuje siÄ™ duÅ¼Ä… zÅ‚oÅ¼onoÅ›ciÄ… decyzyjnÄ…, dynamicznym przebiegiem oraz silnym naciskiem na wspÃ³Å‚pracÄ™ zespoÅ‚owÄ…, 
co czyni jÄ… interesujÄ…cym obiektem analizy z perspektywy danych i uczenia maszynowego.

KaÅ¼dy gracz przed rozpoczÄ™ciem meczu wybiera jednÄ… z 170 postaci. KaÅ¼da postaÄ‡ charakteryzuje siÄ™ innymi umiejÄ™tnoÅ›ciami, stylem gry oraz rodzajem zadawanych obraÅ¼eÅ„. 
NiektÃ³re postacie wspÃ³Å‚grajÄ… ze sobÄ… lepiej, inne gorzej, a niektÃ³re majÄ… przewagÄ™ nad innymi postaciami â€“ tzw. counter postacie.

Kombinacje wyboru postaci majÄ… wiÄ™ksze znaczenie na wyÅ¼szych poziomach rozgrywek. W tym projekcie analizowane sÄ… mecze w przedziale rang **Gold**, ktÃ³ry nie jest wysoki, wiÄ™c wpÅ‚yw wyboru postaci moÅ¼na uznaÄ‡ za mniej istotny.  
Dywizje w League of Legends w kolejnoÅ›ci od najniÅ¼szej do najwyÅ¼szej to:  
Iron, Bronze, Silver, Gold, Platinum, Emerald, Diamond, Master, Challenger.

UmiejÄ™tnoÅ›ci graczy dzielimy na dwie kategorie: **mikro** i **makro**.  
- **Mikro** â€“ umiejÄ™tnoÅ›ci kontroli postaci oraz wiedza o postaciach przeciwnikÃ³w.  
- **Makro** â€“ wszystko inne, czyli rozumienie gry jako caÅ‚oÅ›ci: poruszanie siÄ™ po mapie, zdobywanie celÃ³w, zarzÄ…dzanie falami minionÃ³w i podejmowanie decyzji w druÅ¼ynie.

Na niskim poziomie rozgrywek wiÄ™ksze znaczenie majÄ… umiejÄ™tnoÅ›ci makro, dlatego w projekcie skupiamy siÄ™ na statystykach druÅ¼ynowych, takich jak zÅ‚oto, zabÃ³jstwa i kontrola mapy.

**Szumy w danych:**  
- Pojedynczy gracze zbyt dobrzy lub zbyt sÅ‚abi mogÄ… zaburzaÄ‡ dziaÅ‚anie modelu, wpÅ‚ywajÄ…c na przewidywania wyniku meczu.  
- Na niÅ¼szych rangach zdarzajÄ… siÄ™ nietypowe sytuacje, np. bÅ‚Ä™dne decyzje kilku graczy w jednym momencie, ktÃ³re mogÄ… caÅ‚kowicie zmieniÄ‡ wynik meczu.  

W niniejszym projekcie analizowany jest tryb **Solo/Duo**, w ktÃ³rym gracze mogÄ… doÅ‚Ä…czyÄ‡ do meczu samodzielnie lub w parze, a pozostaÅ‚e miejsca w druÅ¼ynie uzupeÅ‚nia system matchmakingu.  
KaÅ¼dy mecz rozgrywany jest przeciwko innej druÅ¼ynie, a jego wynik wpÅ‚ywa na pozycjÄ™ rankingowÄ… uczestnikÃ³w.

**Struktura meczu:**
- **Early game** â€“ zdobywanie zasobÃ³w, rozwÃ³j postaci, pierwsze starcia.  
- **Mid game** â€“ walki druÅ¼ynowe i kontrola kluczowych obiektÃ³w mapy.  
- **Late game** â€“ pojedyncze decyzje mogÄ… przesÄ…dziÄ‡ o wyniku meczu.

Standardowy mecz League of Legends na mapie Summonerâ€™s Rift trwa Å›rednio **25â€“30 minut**. W niniejszym projekcie analizowane sÄ… **dane do 15. minuty gry**, poniewaÅ¼:  
- w tym czasie najczÄ™Å›ciej ksztaÅ‚tuje siÄ™ przewaga jednej z druÅ¼yn,  
- w 15. minucie rozgrywki gracze uzyskujÄ… moÅ¼liwoÅ›Ä‡ gÅ‚osowania nad poddaniem meczu (surrender).  

Analiza danych do 15. minuty pozwala zatem oceniÄ‡ przewagÄ™ druÅ¼yny w kluczowym momencie meczu. Odpowiedni model predykcyjny mÃ³gÅ‚by pomÃ³c graczom podjÄ…Ä‡ decyzjÄ™ o poddaniu meczu wczeÅ›niej, co potencjalnie **oszczÄ™dza czas gry** i unika niepotrzebnych strat.

**Role w druÅ¼ynie:**
- **Top lane (Top)** â€“ frontline, pojedynki 1v1.  
- **Mid lane (Mid)** â€“ centralna rola, zadawanie obraÅ¼eÅ„, kontrola mapy.  
- **Jungle** â€“ poruszanie siÄ™ po lesie, wsparcie druÅ¼yny, kontrola celÃ³w.  
- **ADC (Attack Damage Carry)** â€“ gÅ‚Ã³wne ÅºrÃ³dÅ‚o obraÅ¼eÅ„ fizycznych.  
- **Support** â€“ ochrona sojusznikÃ³w, inicjacja walk, kontrola wizji.

Na niskich rangach najwiÄ™kszy wpÅ‚yw na rozgrywkÄ™ ma zazwyczaj rola **Jungle**, poniewaÅ¼ gracze koncentrujÄ… siÄ™ na przechwytywaniu duÅ¼ych celÃ³w, ktÃ³re majÄ… znaczÄ…cy wpÅ‚yw na dalszÄ… czÄ™Å›Ä‡ meczu. ZasadnoÅ›Ä‡ tego zaÅ‚oÅ¼enia zostanie sprawdzona w analizie.

**Spodziewane rezultaty:**
- SkutecznoÅ›Ä‡ przewidywania wynikÃ³w meczu ~80%.  
- NajwiÄ™kszy wpÅ‚yw majÄ… zabÃ³jstwa, zÅ‚oto i efektywnoÅ›Ä‡ gry junglera.

**Å¹rÃ³dÅ‚o danych i sposÃ³b pobrania:**  
Na potrzeby projektu dane zostaÅ‚y pobrane za pomocÄ… **API Riot Games**, oficjalnego interfejsu pozwalajÄ…cego na dostÄ™p do statystyk graczy i meczÃ³w League of Legends. Proces pozyskiwania danych przebiegaÅ‚ w nastÄ™pujÄ…cy sposÃ³b:  

1. **Query do dywizji Gold** â€“ pobranie identyfikatorÃ³w graczy (PUUID) z wybranej dywizji.  
2. **Pobranie ostatniego losowego meczu** dla kaÅ¼dego gracza na podstawie PUUID (identyfikatora unikalnego dla gracza).  
3. **Pobranie danych do 15. minuty meczu** (`timeline15`) â€“ czyli informacji o statystykach kaÅ¼dego gracza w kluczowej fazie wczesnej gry.  

DziÄ™ki zostaÅ‚ uzyskany spÃ³jny zbiÃ³r danych, ktÃ³ry pozwala analizowaÄ‡ przewagÄ™ druÅ¼yny w pierwszych 15 minutach i budowaÄ‡ modele predykcyjne przewidujÄ…ce wynik meczu.



**MoÅ¼liwoÅ›ci analizy w czasie rzeczywistym:**  
API Riot Games pozwala rÃ³wnieÅ¼ na pobieranie danych **w trakcie trwania meczu**, co otwiera moÅ¼liwoÅ›Ä‡ tworzenia modeli predykcyjnych dziaÅ‚ajÄ…cych w czasie rzeczywistym.  
Taki model mÃ³gÅ‚by sÅ‚uÅ¼yÄ‡ jako **wirtualny coach** â€“ nie tylko dla pojedynczego gracza, jak robiÄ… narzÄ™dzia typu *Porofessor*, ale dla caÅ‚ej druÅ¼yny.  
Na przykÅ‚ad, analiza danych do 15. minuty mogÅ‚aby pomÃ³c zidentyfikowaÄ‡ **ogÃ³lne problemy w druÅ¼ynie**, wskazaÄ‡ sÅ‚abe punkty i zasugerowaÄ‡ najlepsze decyzje strategiczne, co mogÅ‚oby skrÃ³ciÄ‡ czas gry i zwiÄ™kszyÄ‡ szanse na zwyciÄ™stwo.


""")


# ZaÅ‚aduj dane
data_path = "data/output/gold_full.csv"
df = pd.read_csv(data_path)

# Filtracja remakeâ€™Ã³w
st.sidebar.header("Filtry")
remove_remakes = st.sidebar.checkbox("UsuÅ„ remake'i", True)
if remove_remakes:
    df = df[(df['gold_avg'] >= 1000) & (df['level_avg'] >= 3)]

# WyodrÄ™bnij druÅ¼yny i posortuj
team100 = df[df['teamId'] == 100].copy().sort_values('matchId').reset_index(drop=True)
team200 = df[df['teamId'] == 200].copy().sort_values('matchId').reset_index(drop=True)

# Lista wszystkich kolumn numerycznych do rÃ³Å¼nic
cols_to_diff = [
    'gold_avg',  'cs_avg', 'jungle_cs_avg', 'level_avg', 'xp_avg',
    'total_damage_done_avg', 'total_damage_taken_avg', 'damage_to_champions_avg',
    'kills_avg',  'assists_avg',
    'towers', 'dragons',  'first_blood', 'first_tower', 'first_dragon' 
]

# Tworzymy dataframe z rÃ³Å¼nicami
df_matches = pd.DataFrame()
df_matches['matchId'] = team100['matchId']
for col in cols_to_diff:
    df_matches[col + '_diff'] = team100[col] - team200[col]

# Zmienna celu
df_matches['win_team100'] = team100['win']

# Reset indeksu
df_matches = df_matches.reset_index(drop=True)

#st.write("Liczba wierszy po filtracji:", df.shape[0])
#st.write("Liczba meczÃ³w po poÅ‚Ä…czeniu druÅ¼yn:", df_matches.shape[0])

#Podstawowe statystyki nowych cech
st.subheader("Podstawowe statystyki rÃ³Å¼nic druÅ¼yn")
st.dataframe(df_matches.describe().T)


st.markdown("""
- **gold_avg_diff** â€“ rÃ³Å¼nica Å›redniego zÅ‚ota miÄ™dzy druÅ¼ynami (team100 â€“ team200). ZÅ‚oto pozwala kupowaÄ‡ przedmioty zwiÄ™kszajÄ…ce siÅ‚Ä™ postaci, wiÄ™c przewaga w zÅ‚ocie zwykle daje lepsze moÅ¼liwoÅ›ci w walce.  
- **cs_avg_diff** â€“ rÃ³Å¼nica Å›redniej liczby zabitych jednostek (minionÃ³w/monsterÃ³w) miÄ™dzy druÅ¼ynami. WiÄ™cej CS = wiÄ™cej zÅ‚ota i doÅ›wiadczenia.  
- **jungle_cs_avg_diff** â€“ rÃ³Å¼nica Å›redniej liczby potworÃ³w zabitych przez junglera druÅ¼yny. Kontrola jungli wpÅ‚ywa na przewagÄ™ strategicznÄ… i dostÄ™p do celÃ³w mapy.  
- **level_avg_diff** â€“ rÃ³Å¼nica Å›redniego poziomu postaci miÄ™dzy druÅ¼ynami. WyÅ¼szy poziom daje lepsze umiejÄ™tnoÅ›ci i wiÄ™kszÄ… siÅ‚Ä™ w walkach.  
- **xp_avg_diff** â€“ rÃ³Å¼nica Å›redniego doÅ›wiadczenia (experience) zdobytego przez graczy. WyÅ¼sze XP pozwala szybciej zdobywaÄ‡ poziomy i umiejÄ™tnoÅ›ci.  
- **total_damage_done_avg_diff** â€“ rÃ³Å¼nica Å›redniego zadawanych obraÅ¼eÅ„ (wszystkie ÅºrÃ³dÅ‚a) druÅ¼yn. Pokazuje, ktÃ³ra druÅ¼yna jest agresywniejsza i skuteczniejsza w zadawaniu obraÅ¼eÅ„.  
- **total_damage_taken_avg_diff** â€“ rÃ³Å¼nica Å›rednich obraÅ¼eÅ„ otrzymanych przez druÅ¼yny. MoÅ¼e wskazywaÄ‡, ktÃ³ra druÅ¼yna jest bardziej odporna lub lepiej pozycjonuje swoich graczy.  
- **damage_to_champions_avg_diff** â€“ rÃ³Å¼nica Å›rednich obraÅ¼eÅ„ zadanych przeciwnym bohaterom (champions). WaÅ¼ny wskaÅºnik skutecznoÅ›ci w walkach druÅ¼ynowych.  
- **kills_avg_diff** â€“ rÃ³Å¼nica Å›redniej liczby zabÃ³jstw bohaterÃ³w przeciwnika. BezpoÅ›rednio wpÅ‚ywa na przewagÄ™ w zÅ‚ocie i kontroli mapy.  
- **assists_avg_diff** â€“ rÃ³Å¼nica Å›redniej liczby asyst w zabÃ³jstwach. Pokazuje wspÃ³Å‚pracÄ™ druÅ¼ynowÄ… i skutecznoÅ›Ä‡ w wspieraniu sojusznikÃ³w.  
- **towers_diff** â€“ rÃ³Å¼nica liczby zniszczonych wieÅ¼ przez druÅ¼yny. Kontrolowanie wieÅ¼ daje przewagÄ™ na mapie i dostÄ™p do wrogiego terytorium.  
- **dragons_diff** â€“ rÃ³Å¼nica liczby smokÃ³w zabitych przez druÅ¼yny. Smoki dajÄ… trwaÅ‚e bonusy, wiÄ™c ich przewaga jest strategicznie istotna.  
- **first_blood_diff** â€“ rÃ³Å¼nica, ktÃ³ra druÅ¼yna zdobyÅ‚a pierwszÄ… krew (pierwsze zabÃ³jstwo). Pierwsze zabÃ³jstwo daje dodatkowe zÅ‚oto i przewagÄ™ psychologicznÄ….  
- **first_tower_diff** â€“ rÃ³Å¼nica, ktÃ³ra druÅ¼yna zniszczyÅ‚a pierwszÄ… wieÅ¼Ä™. Pierwsza wieÅ¼a daje dodatkowe zÅ‚oto i kontrolÄ™ mapy.  
- **first_dragon_diff** â€“ rÃ³Å¼nica, ktÃ³ra druÅ¼yna zdobyÅ‚a pierwszego smoka. Pierwszy smok daje druÅ¼ynie przewagÄ™ w buffach.  
- **win_team100** â€“ zmienna celu, 1 jeÅ›li druÅ¼yna 100 wygraÅ‚a mecz, 0 jeÅ›li przegraÅ‚a.
""")
# Heatmapa korelacji
st.subheader("Mapa korelacji cech (rÃ³Å¼nice druÅ¼yn)")
numeric_cols = df_matches.select_dtypes(include=['int64', 'float64']).drop(columns=['win_team100'])
fig, ax = plt.subplots(figsize=(12,8))
sns.heatmap(numeric_cols.corr(), annot=True, fmt=".2f", cmap='coolwarm', ax=ax)
st.pyplot(fig)

st.markdown("""
### Analiza korelacji cech

Na podstawie mapy korelacji widzimy, Å¼e niektÃ³re cechy sÄ… silnie ze sobÄ… powiÄ…zane, co jest naturalne w kontekÅ›cie gry:

- **gold_avg_diff** silnie koreluje z **xp_avg_diff** (0.89) i **kills_avg_diff** (0.89), co pokazuje, Å¼e przewaga w zÅ‚ocie idzie w parze z przewagÄ… w poziomach postaci oraz liczbie zabÃ³jstw.  
- **level_avg_diff** i **xp_avg_diff** majÄ… bardzo wysokÄ… korelacjÄ™ (0.94), co jest logiczne, bo wyÅ¼szy poziom postaci wynika z wiÄ™kszego doÅ›wiadczenia zdobytego w grze.  
- **towers_diff** jest mocno skorelowane ujemnie z **gold_avg_diff** (-0.76) i **first_tower_diff** (0.87), co wskazuje, Å¼e pierwsza wieÅ¼a daje znacznÄ… przewagÄ™ w zÅ‚ocie i kontroli mapy.  
- **dragons_diff** i **first_dragon_diff** sÄ… bardzo silnie skorelowane (0.95), co pokazuje, Å¼e druÅ¼yna, ktÃ³ra zdobywa pierwszego smoka, zdobywa ich wiÄ™cej w ciÄ…gu gry, lub do 15 minuty wiÄ™kszoÅ›Ä‡ druÅ¼yn zdobywa tylko jednego smoka.  
- **damage_to_champions_avg_diff** i **kills_avg_diff** majÄ… wysokÄ… korelacjÄ™ (0.71), co pokazuje, Å¼e druÅ¼yny z wiÄ™kszÄ… liczbÄ… zabÃ³jstw zadajÄ… teÅ¼ wiÄ™cej obraÅ¼eÅ„ bohaterom przeciwnika.  
- **assists_avg_diff** jest umiarkowanie skorelowane z **kills_avg_diff** (0.78), co pokazuje, Å¼e wspÃ³Å‚praca druÅ¼ynowa przy zabÃ³jstwach ma znaczenie.  

Wnioski dla modelu:
- NiektÃ³re cechy sÄ… mocno skorelowane (np. zÅ‚oto, XP, level, kills). Z pewnoÅ›ciÄ… bÄ™dÄ… one miaÅ‚y duÅ¼y wpÅ‚yw na wynik meczu. 
- Cechy dotyczÄ…ce pierwszych celÃ³w (first_blood_diff, first_tower_diff, first_dragon_diff) majÄ… mniejsze korelacje z innymi zmiennymi, ale mogÄ… mieÄ‡ duÅ¼y wpÅ‚yw psychologiczny i strategiczny na wynik meczu.  
- Wysokie korelacje miÄ™dzy **dragon_diff** a **first_dragon_diff** oraz **tower_diff** a **first_tower_diff** sÄ… sensowne. Silna korelacja oznacza, Å¼e zdobycie pierwszych celÃ³w moÅ¼e pozytywnie wpÅ‚ywaÄ‡ na dalszÄ… rozgrywkÄ™, natomiast sytuacje, gdy druÅ¼yna zdobywa pierwszy cel, lecz ma mniej celÃ³w do 15 minuty, potencjalnie Å›wiadczÄ… o rÃ³Å¼nicach sytuacji miÄ™dzy poszczegÃ³lnymi liniami.
""")

# PodglÄ…d danych
#st.subheader("PodglÄ…d danych po poÅ‚Ä…czeniu druÅ¼yn")
#n_rows = st.sidebar.slider("Liczba wierszy do podglÄ…du:", min_value=5, max_value=50, value=10)
#st.dataframe(df_matches.head(n_rows))

# ========================================================================
# EKSPLORACYJNA ANALIZA DANYCH (EDA)
# ========================================================================
st.header("Eksploracyjna Analiza Danych (EDA)")

# Balans klas
st.subheader("Balans klas - RozkÅ‚ad wynikÃ³w (win_team100)")
win_counts = df_matches['win_team100'].value_counts()
st.write(f"**Przegrane druÅ¼yny (team100):** {win_counts.get(0, 0)} ({win_counts.get(0, 0)/len(df_matches)*100:.2f}%)")
st.write(f"**Wygrane druÅ¼yny (team100):** {win_counts.get(1, 0)} ({win_counts.get(1, 0)/len(df_matches)*100:.2f}%)")

fig, ax = plt.subplots(figsize=(8, 5))
win_counts.plot(kind='bar', ax=ax, color=['#d62728', '#2ca02c'])
ax.set_title('RozkÅ‚ad wynikÃ³w meczÃ³w', fontsize=14, fontweight='bold')
ax.set_xlabel('Wynik (0 = przegrana, 1 = wygrana)')
ax.set_ylabel('Liczba meczÃ³w')
ax.set_xticklabels(['Przegrana', 'Wygrana'], rotation=0)
for container in ax.containers:
    ax.bar_label(container)
st.pyplot(fig)

# Analiza rozkÅ‚adÃ³w kluczowych zmiennych
st.subheader("RozkÅ‚ad kluczowych zmiennych")
key_features = ['gold_avg_diff', 'kills_avg_diff', 'cs_avg_diff', 
                'xp_avg_diff', 'damage_to_champions_avg_diff', 'towers_diff']

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()
for i, col in enumerate(key_features):
    axes[i].hist(df_matches[col], bins=30, edgecolor='black', alpha=0.7)
    axes[i].set_title(col, fontweight='bold')
    axes[i].set_xlabel('WartoÅ›Ä‡ rÃ³Å¼nicy')
    axes[i].set_ylabel('CzÄ™stoÅ›Ä‡')
    axes[i].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')
    axes[i].legend()
plt.tight_layout()
st.pyplot(fig)

# Boxploty - porÃ³wnanie cech w zaleÅ¼noÅ›ci od wyniku
st.subheader("Boxploty cech w zaleÅ¼noÅ›ci od wyniku meczu")
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()
for i, col in enumerate(key_features):
    df_matches.boxplot(column=col, by='win_team100', ax=axes[i])
    axes[i].set_title(col)
    axes[i].set_xlabel('Wynik (0 = przegrana, 1 = wygrana)')
    axes[i].set_ylabel('WartoÅ›Ä‡ rÃ³Å¼nicy')
plt.suptitle('')
plt.tight_layout()
st.pyplot(fig)

st.markdown("""
### Wnioski z Analizy Eksploracyjnej (EDA)

#### 1. Balans Klas (Wynik Meczu)
* **Zbalansowany ZbiÃ³r:** RozkÅ‚ad zwyciÄ™stw i poraÅ¼ek jest zbliÅ¼ony do proporcji **50/50** (z lekkim wskazaniem na jednÄ… ze stron). To kluczowa informacja, ktÃ³ra sugeruje, Å¼e dane sÄ… reprezentatywne i nie wymagajÄ… stosowania technik takich jak oversampling czy undersampling przed przystÄ…pieniem do modelowania.

#### 2. RozkÅ‚ady Kluczowych Zmiennych (Histogramy)
* **Symetria RozkÅ‚adÃ³w:** WiÄ™kszoÅ›Ä‡ cech rÃ³Å¼nicowych (gold, xp, kills, cs, damage) wykazuje **rozkÅ‚ad normalny (Gaussa)** wycentrowany wokÃ³Å‚ zera. 
* **Charakterystyka Rozgrywek:** Fakt, Å¼e wiÄ™kszoÅ›Ä‡ obserwacji skupia siÄ™ blisko zera, Å›wiadczy o tym, Å¼e wiÄ™kszoÅ›Ä‡ meczÃ³w w zbiorze to starcia stosunkowo wyrÃ³wnane. Skrajne przewagi (tzw. "stompy") stanowiÄ… mniejszoÅ›Ä‡ statystycznÄ….
* **DyskretnoÅ›Ä‡ WieÅ¼:** RÃ³Å¼nica w zniszczonych wieÅ¼ach (`towers_diff`) jako jedyna ma charakter skokowy, co wynika z natury tego obiektu w grze.

#### 3. WpÅ‚yw Cech na Wynik (Boxploty)
* **Ekonomia i DoÅ›wiadczenie (Gold & XP):** To najsilniejsze predyktory zwyciÄ™stwa. Mediany dla wygranych i przegranych sÄ… wyraÅºnie odseparowane. Wygrana druÅ¼yna niemal zawsze utrzymuje dodatniÄ… rÃ³Å¼nicÄ™ w zÅ‚ocie i doÅ›wiadczeniu.
* **ZabÃ³jstwa (Kills) vs. Farma (CS):** Obie cechy silnie korelujÄ… z wynikiem, jednak rÃ³Å¼nica w CS (`cs_avg_diff`) wykazuje mniejszÄ… liczbÄ™ wartoÅ›ci odstajÄ…cych w porÃ³wnaniu do zabÃ³jstw. Sugeruje to, Å¼e stabilna przewaga w farmie jest bezpieczniejszym wskaÅºnikiem wygranej niÅ¼ agresywne szukanie zabÃ³jstw.
* **ObraÅ¼enia (Damage to Champions):** Co ciekawe, mimo Å¼e wygrani zadajÄ… Å›rednio wiÄ™cej obraÅ¼eÅ„, pudeÅ‚ka (interquartile range) w duÅ¼ej mierze siÄ™ pokrywajÄ…. Oznacza to, Å¼e same obraÅ¼enia nie sÄ… tak determinujÄ…ce jak zdobyte zÅ‚oto czy cele mapy.
* **Struktury (Towers):** WyraÅºna separacja w `towers_diff` potwierdza, Å¼e niszczenie wieÅ¼ jest bezpoÅ›rednio powiÄ…zane z wynikiem meczu â€“ mediana dla przegranych znajduje siÄ™ poniÅ¼ej zera, podczas gdy dla wygranych jest wyraÅºnie dodatnia.

#### 4. Podsumowanie dla Modelowania
* Cechy oparte na **zasobach (Gold, XP)** bÄ™dÄ… miaÅ‚y najwiÄ™kszÄ… wagÄ™ w modelu.
* WystÄ™powanie wartoÅ›ci odstajÄ…cych (outliers) w statystykach zabÃ³jstw i obraÅ¼eÅ„ sugeruje, Å¼e model powinien byÄ‡ odporny na szum (np. algorytmy drzewiaste jak XGBoost czy LightGBM).
""")

# ========================================================================
#  PRZYGOTOWANIE DANYCH
# ========================================================================
st.header("Przygotowanie danych do modelowania")

# WybÃ³r cech i zmiennej celu
X = df_matches.drop(columns=['matchId', 'win_team100'])
y = df_matches['win_team100']

st.write(f"**Liczba cech:** {X.shape[1]}")
st.write(f"**Liczba obserwacji:** {X.shape[0]}")
st.write(f"**Lista cech:** {list(X.columns)}")

# PodziaÅ‚ na zbiÃ³r uczÄ…cy i testowy
test_size = st.sidebar.slider("Rozmiar zbioru testowego (%):", min_value=10, max_value=40, value=20) / 100
random_state = 42

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=random_state, stratify=y
)

st.write(f"**ZbiÃ³r uczÄ…cy:** {X_train.shape[0]} obserwacji")
st.write(f"**ZbiÃ³r testowy:** {X_test.shape[0]} obserwacji")

# Standaryzacja cech
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

st.write("Dane zostaÅ‚y wystandaryzowane (Å›rednia=0, odchylenie standardowe=1)")

# 1ï¸âƒ£4ï¸âƒ£ Opcjonalnie: SMOTE (oversampling) jeÅ›li klasy sÄ… niezbalansowane
#use_smote = st.sidebar.checkbox("UÅ¼yj SMOTE (oversampling)", False)
#if use_smote:
 #   smote = SMOTE(random_state=random_state)
 #   X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)
 #   st.write(f" SMOTE zastosowany. Nowa liczba obserwacji w zbiorze uczÄ…cym: {X_train_scaled.shape[0]}")

# ========================================================================
# MODELOWANIE - UCZENIE MASZYNOWE
# ========================================================================
st.header("Modelowanie - Uczenie Maszynowe")

st.markdown("""
W tej sekcji zastosujemy **4 rÃ³Å¼ne metody uczenia maszynowego**:
1. **Regresja logistyczna** - model liniowy, baseline
2. **K-Nearest Neighbors (KNN)** - metoda oparta na odlegÅ‚oÅ›ciach
3. **Drzewa decyzyjne** - model nieparametryczny, Å‚atwo interpretowalny
4. **Support Vector Machine (SVM)** - model oparty na maksymalizacji marginesu

Dla kaÅ¼dego modelu przeprowadzimy **optymalizacjÄ™ hiperparametrÃ³w** oraz **walidacjÄ™ krzyÅ¼owÄ…**.
""")

# SÅ‚ownik do przechowywania wynikÃ³w
results = {}

# ========================================================================
# MODEL 1: REGRESJA LOGISTYCZNA
# ========================================================================
st.subheader("Regresja Logistyczna")

with st.spinner("Trening modelu regresji logistycznej..."):
    # Optymalizacja hiperparametrÃ³w
    param_grid_lr = {
        'C': [0.01, 0.1, 1, 10, 100],
        'penalty': ['l2'],
        'solver': ['lbfgs']
    }
    
    lr = LogisticRegression(max_iter=1000, random_state=random_state)
    grid_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)
    grid_lr.fit(X_train_scaled, y_train)
    
    best_lr = grid_lr.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_lr.best_params_}")
    
    # Predykcje
    y_pred_lr = best_lr.predict(X_test_scaled)
    y_pred_proba_lr = best_lr.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_lr = accuracy_score(y_test, y_pred_lr)
    prec_lr = precision_score(y_test, y_pred_lr)
    rec_lr = recall_score(y_test, y_pred_lr)
    f1_lr = f1_score(y_test, y_pred_lr)
    auc_lr = roc_auc_score(y_test, y_pred_proba_lr)
    
    results['Logistic Regression'] = {
        'model': best_lr,
        'y_pred': y_pred_lr,
        'y_pred_proba': y_pred_proba_lr,
        'accuracy': acc_lr,
        'precision': prec_lr,
        'recall': rec_lr,
        'f1': f1_lr,
        'auc': auc_lr
    }
    
    st.write(f"**Accuracy:** {acc_lr:.4f}")
    st.write(f"**Precision:** {prec_lr:.4f}")
    st.write(f"**Recall:** {rec_lr:.4f}")
    st.write(f"**F1-Score:** {f1_lr:.4f}")
    st.write(f"**AUC-ROC:** {auc_lr:.4f}")

# ========================================================================
# MODEL 2: K-NEAREST NEIGHBORS (KNN)
# ========================================================================
st.subheader("K-Nearest Neighbors (KNN)")

with st.spinner("Trening modelu KNN..."):
    # Optymalizacja hiperparametrÃ³w
    param_grid_knn = {
        'n_neighbors': [3, 5, 7, 9, 11, 15],
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean', 'manhattan']
    }
    
    knn = KNeighborsClassifier()
    grid_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)
    grid_knn.fit(X_train_scaled, y_train)
    
    best_knn = grid_knn.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_knn.best_params_}")
    
    # Predykcje
    y_pred_knn = best_knn.predict(X_test_scaled)
    y_pred_proba_knn = best_knn.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_knn = accuracy_score(y_test, y_pred_knn)
    prec_knn = precision_score(y_test, y_pred_knn)
    rec_knn = recall_score(y_test, y_pred_knn)
    f1_knn = f1_score(y_test, y_pred_knn)
    auc_knn = roc_auc_score(y_test, y_pred_proba_knn)
    
    results['KNN'] = {
        'model': best_knn,
        'y_pred': y_pred_knn,
        'y_pred_proba': y_pred_proba_knn,
        'accuracy': acc_knn,
        'precision': prec_knn,
        'recall': rec_knn,
        'f1': f1_knn,
        'auc': auc_knn
    }
    
    st.write(f"**Accuracy:** {acc_knn:.4f}")
    st.write(f"**Precision:** {prec_knn:.4f}")
    st.write(f"**Recall:** {rec_knn:.4f}")
    st.write(f"**F1-Score:** {f1_knn:.4f}")
    st.write(f"**AUC-ROC:** {auc_knn:.4f}")

# ========================================================================
# MODEL 3: DRZEWA DECYZYJNE
# ========================================================================
st.subheader("Drzewa Decyzyjne")

with st.spinner("Trening modelu drzewa decyzyjnego..."):
    # Optymalizacja hiperparametrÃ³w
    param_grid_dt = {
        'max_depth': [3, 5, 7, 10, 15, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'criterion': ['gini', 'entropy']
    }
    
    dt = DecisionTreeClassifier(random_state=random_state)
    grid_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1)
    grid_dt.fit(X_train_scaled, y_train)
    
    best_dt = grid_dt.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_dt.best_params_}")
    
    # Predykcje
    y_pred_dt = best_dt.predict(X_test_scaled)
    y_pred_proba_dt = best_dt.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_dt = accuracy_score(y_test, y_pred_dt)
    prec_dt = precision_score(y_test, y_pred_dt)
    rec_dt = recall_score(y_test, y_pred_dt)
    f1_dt = f1_score(y_test, y_pred_dt)
    auc_dt = roc_auc_score(y_test, y_pred_proba_dt)
    
    results['Decision Tree'] = {
        'model': best_dt,
        'y_pred': y_pred_dt,
        'y_pred_proba': y_pred_proba_dt,
        'accuracy': acc_dt,
        'precision': prec_dt,
        'recall': rec_dt,
        'f1': f1_dt,
        'auc': auc_dt
    }
    
    st.write(f"**Accuracy:** {acc_dt:.4f}")
    st.write(f"**Precision:** {prec_dt:.4f}")
    st.write(f"**Recall:** {rec_dt:.4f}")
    st.write(f"**F1-Score:** {f1_dt:.4f}")
    st.write(f"**AUC-ROC:** {auc_dt:.4f}")
    
    # Wizualizacja drzewa
    st.write("**Wizualizacja drzewa decyzyjnego:**")
    fig, ax = plt.subplots(figsize=(20, 10))
    plot_tree(best_dt, ax=ax, feature_names=X.columns, class_names=['Loss', 'Win'], 
              filled=True, rounded=True, fontsize=10)
    st.pyplot(fig)

# ========================================================================
# MODEL 4: SUPPORT VECTOR MACHINE (SVM)
# ========================================================================
st.subheader("Support Vector Machine (SVM)")

with st.spinner("Trening modelu SVM..."):
    # Optymalizacja hiperparametrÃ³w (ograniczony grid ze wzglÄ™du na czas)
    param_grid_svm = {
        'C': [0.1, 1, 10],
        'kernel': ['linear', 'rbf'],
        'gamma': ['scale', 'auto']
    }
    
    svm = SVC(probability=True, random_state=random_state)
    grid_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring='accuracy', n_jobs=-1)
    grid_svm.fit(X_train_scaled, y_train)
    
    best_svm = grid_svm.best_estimator_
    st.write(f"**Najlepsze parametry:** {grid_svm.best_params_}")
    
    # Predykcje
    y_pred_svm = best_svm.predict(X_test_scaled)
    y_pred_proba_svm = best_svm.predict_proba(X_test_scaled)[:, 1]
    
    # Metryki
    acc_svm = accuracy_score(y_test, y_pred_svm)
    prec_svm = precision_score(y_test, y_pred_svm)
    rec_svm = recall_score(y_test, y_pred_svm)
    f1_svm = f1_score(y_test, y_pred_svm)
    auc_svm = roc_auc_score(y_test, y_pred_proba_svm)
    
    results['SVM'] = {
        'model': best_svm,
        'y_pred': y_pred_svm,
        'y_pred_proba': y_pred_proba_svm,
        'accuracy': acc_svm,
        'precision': prec_svm,
        'recall': rec_svm,
        'f1': f1_svm,
        'auc': auc_svm
    }
    
    st.write(f"**Accuracy:** {acc_svm:.4f}")
    st.write(f"**Precision:** {prec_svm:.4f}")
    st.write(f"**Recall:** {rec_svm:.4f}")
    st.write(f"**F1-Score:** {f1_svm:.4f}")
    st.write(f"**AUC-ROC:** {auc_svm:.4f}")

# ========================================================================
# PORÃ“WNANIE MODELI
# ========================================================================
st.header("PorÃ³wnanie modeli")

# Tabela porÃ³wnawcza
comparison_df = pd.DataFrame({
    'Model': list(results.keys()),
    'Accuracy': [results[m]['accuracy'] for m in results.keys()],
    'Precision': [results[m]['precision'] for m in results.keys()],
    'Recall': [results[m]['recall'] for m in results.keys()],
    'F1-Score': [results[m]['f1'] for m in results.keys()],
    'AUC-ROC': [results[m]['auc'] for m in results.keys()]
})

st.dataframe(comparison_df.style.highlight_max(axis=0, subset=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']))

# Wykres porÃ³wnawczy
fig, ax = plt.subplots(figsize=(12, 6))
comparison_df.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']].plot(
    kind='bar', ax=ax, rot=0
)
ax.set_title('PorÃ³wnanie metryk dla rÃ³Å¼nych modeli', fontsize=14, fontweight='bold')
ax.set_ylabel('WartoÅ›Ä‡ metryki')
ax.set_ylim([0, 1])
ax.legend(loc='lower right')
ax.grid(axis='y', alpha=0.3)
st.pyplot(fig)

# Macierze konfuzji
st.subheader("Macierze konfuzji")
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for idx, (model_name, model_data) in enumerate(results.items()):
    cm = confusion_matrix(y_test, model_data['y_pred'])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx], 
                xticklabels=['Loss', 'Win'], yticklabels=['Loss', 'Win'])
    axes[idx].set_title(f'{model_name}', fontweight='bold')
    axes[idx].set_ylabel('Rzeczywista klasa')
    axes[idx].set_xlabel('Przewidywana klasa')

plt.tight_layout()
st.pyplot(fig)

# Krzywe ROC
st.subheader("Krzywe ROC")
fig, ax = plt.subplots(figsize=(10, 8))

for model_name, model_data in results.items():
    fpr, tpr, _ = roc_curve(y_test, model_data['y_pred_proba'])
    ax.plot(fpr, tpr, label=f"{model_name} (AUC = {model_data['auc']:.3f})", linewidth=2)

ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)
ax.set_xlabel('False Positive Rate', fontsize=12)
ax.set_ylabel('True Positive Rate', fontsize=12)
ax.set_title('Krzywe ROC - PorÃ³wnanie modeli', fontsize=14, fontweight='bold')
ax.legend(loc='lower right')
ax.grid(alpha=0.3)
st.pyplot(fig)

# ========================================================================
# INTERPRETOWALNOÅšÄ† - SHAP VALUES
# ========================================================================
st.header("ğŸ” InterpretowalnoÅ›Ä‡ modelu - SHAP Values")

st.markdown("""
**SHAP (SHapley Additive exPlanations)** to metoda wyjaÅ›niania predykcji modeli uczenia maszynowego 
oparta na teorii gier kooperacyjnych. WartoÅ›ci SHAP pokazujÄ…, jak kaÅ¼da cecha wpÅ‚ywa na predykcjÄ™ modelu.

Analizujemy interpretowalnoÅ›Ä‡ **najlepszego modelu** na podstawie F1-Score.
""")

# WybÃ³r najlepszego modelu
best_model_name = comparison_df.loc[comparison_df['F1-Score'].idxmax(), 'Model']
best_model = results[best_model_name]['model']

st.write(f"**Najlepszy model:** {best_model_name} (F1-Score: {results[best_model_name]['f1']:.4f})")

with st.spinner("Obliczanie wartoÅ›ci SHAP... (moÅ¼e potrwaÄ‡ kilka minut)"):
    # SHAP dla rÃ³Å¼nych typÃ³w modeli
    if best_model_name == 'Decision Tree':
        explainer = shap.TreeExplainer(best_model)
        shap_values = explainer.shap_values(X_test_scaled)
        if isinstance(shap_values, list):
            shap_values = shap_values[1]  # Dla klasy pozytywnej (win)
    elif best_model_name in ['Logistic Regression', 'SVM']:
        explainer = shap.LinearExplainer(best_model, X_train_scaled)
        shap_values = explainer.shap_values(X_test_scaled)
    else:  # KNN
        explainer = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_train_scaled, 100))
        shap_values = explainer.shap_values(X_test_scaled)
        if isinstance(shap_values, list):
            shap_values = shap_values[1]
    
    # Summary plot (waÅ¼noÅ›Ä‡ cech)
    st.subheader("WaÅ¼noÅ›Ä‡ cech - SHAP Summary Plot")
    fig, ax = plt.subplots(figsize=(10, 8))
    shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, show=False)
    st.pyplot(fig)
    
    # Bar plot (Å›rednia wartoÅ›Ä‡ SHAP)
    st.subheader("Åšrednia wartoÅ›Ä‡ SHAP dla kaÅ¼dej cechy")
    fig, ax = plt.subplots(figsize=(10, 8))
    shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, plot_type='bar', show=False)
    st.pyplot(fig)
    
    # Waterfall plot dla przykÅ‚adowej obserwacji
    st.subheader("SHAP Waterfall Plot - PrzykÅ‚adowa predykcja")
    sample_idx = st.slider("Wybierz indeks obserwacji do analizy:", 0, len(X_test_scaled)-1, 0)
    
    fig, ax = plt.subplots(figsize=(10, 8))
    shap_explanation = shap.Explanation(
        values=shap_values[sample_idx], 
        base_values=explainer.expected_value if not isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value[1],
        data=X_test_scaled[sample_idx],
        feature_names=X.columns
    )
    shap.waterfall_plot(shap_explanation, show=False)
    st.pyplot(fig)
    
    actual_label = "Wygrana" if y_test.iloc[sample_idx] == 1 else "Przegrana"
    predicted_label = "Wygrana" if results[best_model_name]['y_pred'][sample_idx] == 1 else "Przegrana"
    st.write(f"**Rzeczywista klasa:** {actual_label}")
    st.write(f"**Przewidywana klasa:** {predicted_label}")

st.markdown("""
### Interpretacja SHAP:
- **Summary plot (beeswarm)**: Pokazuje wpÅ‚yw kaÅ¼dej cechy na predykcje. Kolor wskazuje wartoÅ›Ä‡ cechy (czerwony = wysoka, niebieski = niska), 
  pozycja na osi X pokazuje wartoÅ›Ä‡ SHAP (wpÅ‚yw na predykcjÄ™).
- **Bar plot**: Pokazuje Å›redniÄ… absolutnÄ… wartoÅ›Ä‡ SHAP dla kaÅ¼dej cechy - im wyÅ¼sza, tym waÅ¼niejsza cecha.
- **Waterfall plot**: Pokazuje, jak poszczegÃ³lne cechy przyczyniÅ‚y siÄ™ do konkretnej predykcji, zaczynajÄ…c od wartoÅ›ci bazowej (Å›redniej predykcji).
""")

# ========================================================================
# PODSUMOWANIE I WNIOSKI
# ========================================================================
st.header("Podsumowanie i Wnioski")

st.markdown(f"""
### Podsumowanie projektu:

**Cel projektu:**  
Przewidywanie wyniku meczu League of Legends (wygrana/przegrana) na podstawie danych zebranych do 15. minuty gry.

**Dane:**  
- Liczba meczÃ³w: {len(df_matches)}
- Liczba cech: {X.shape[1]} (rÃ³Å¼nice miÄ™dzy druÅ¼ynami)
- Balans klas: {win_counts.get(0, 0)} przegranych vs {win_counts.get(1, 0)} wygranych

**Zastosowane metody:**
1. **Regresja Logistyczna** - baseline model liniowy
2. **K-Nearest Neighbors (KNN)** - metoda oparta na podobieÅ„stwie
3. **Drzewa Decyzyjne** - model nieparametryczny, interpretowalny
4. **Support Vector Machine (SVM)** - maksymalizacja marginesu decyzyjnego

**Najlepszy model:**  
**{best_model_name}** osiÄ…gnÄ…Å‚ najwyÅ¼szy F1-Score: **{results[best_model_name]['f1']:.4f}**

**Kluczowe obserwacje:**

1. **SkutecznoÅ›Ä‡ predykcji**: Wszystkie modele osiÄ…gnÄ™Å‚y wysokÄ… dokÅ‚adnoÅ›Ä‡ (accuracy > 80%), co sugeruje, 
   Å¼e dane z pierwszych 15 minut meczu zawierajÄ… istotne sygnaÅ‚y predykcyjne.

2. **NajwaÅ¼niejsze cechy** (na podstawie SHAP):
   - `gold_avg_diff` - rÃ³Å¼nica w zdobytym zÅ‚ocie jest kluczowym wskaÅºnikiem przewagi
   - `kills_avg_diff` - rÃ³Å¼nica w eliminacjach wpÅ‚ywa znaczÄ…co na wynik
   - `xp_avg_diff` - rÃ³Å¼nica w doÅ›wiadczeniu (poziomach) jest istotna
   - `towers_diff` - zdobyte wieÅ¼e dajÄ… duÅ¼Ä… przewagÄ™ strategicznÄ…

3. **PorÃ³wnanie modeli**:
   - **SVM i Logistic Regression** radzÄ… sobie najlepiej na tym zbiorze danych (liniowa separowalnoÅ›Ä‡)
   - **Decision Tree** oferuje dobrÄ… interpretowalnoÅ›Ä‡, ale moÅ¼e byÄ‡ podatny na overfitting
   - **KNN** dziaÅ‚a dobrze, ale wymaga standaryzacji danych

4. **Wnioski strategiczne**:
   - Wczesna przewaga w zÅ‚ocie i doÅ›wiadczeniu jest silnym predyktorem koÅ„cowego wyniku
   - Kontrola obiektywÃ³w (wieÅ¼e, smoki) juÅ¼ w pierwszych 15 minutach ma znaczÄ…cy wpÅ‚yw
   - Wysokie kill/death ratio koreluje z wygranÄ…, ale nie jest jedynym czynnikiem

**Potencjalne usprawnienia:**
- Dodanie feature engineering (np. interakcje miÄ™dzy cechami)
- Zastosowanie ensemble methods (Random Forest, XGBoost)
- Analiza rÃ³Å¼nic w rÃ³Å¼nych dywizjach rankingowych
- UwzglÄ™dnienie dodatkowych danych (np. pick/ban, role graczy)

**Ograniczenia:**
- Analiza oparta wyÅ‚Ä…cznie na dywizji Gold - wyniki mogÄ… siÄ™ rÃ³Å¼niÄ‡ dla innych rankingÃ³w
- Nie uwzglÄ™dniono czynnikÃ³w jakoÅ›ciowych (komunikacja zespoÅ‚owa, psychologia)
- Dane pochodzÄ… z konkretnego okresu - meta gry moÅ¼e siÄ™ zmieniaÄ‡
""")

st.success("Projekt streamlit zakoÅ„czony pomyÅ›lnie")

